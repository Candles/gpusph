/*  Copyright 2013 Alexis Herault, Giuseppe Bilotta, Robert A.
 	Dalrymple, Eugenio Rustico, Ciro Del Negro

	Conservatoire National des Arts et Metiers, Paris, France

	Istituto Nazionale di Geofisica e Vulcanologia,
    Sezione di Catania, Catania, Italy

    Universita di Catania, Catania, Italy

    Johns Hopkins University, Baltimore, MD

	This file is part of GPUSPH.

    GPUSPH is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    GPUSPH is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with GPUSPH.  If not, see <http://www.gnu.org/licenses/>.
*/

#ifndef _FORCES_KERNEL_AUX
#define _FORCES_KERNEL_AUX

#include <type_traits> // for std::is_base_of

/// This file defines the heavy-duty forcesDevice kernel (at the end).
/// The kernel itself is now quite streamlined, and it only contains sequences
/// of calls to templatized functors that do the actual job according to their
/// specialization (based on SPH formulation, boundary type, viscosity type, etc).
/// The functors themselves operate on sets of data structures which are also
/// templatized based on the same parameters, and that include only the
/// variables actually needed for each specialization.

/// Some hints:
/// * const-ify everything that can be made const
/// * if the initialization of a would-be const member is complex, define an
///   auxiliary function for it
/// * functors use the 'with' operator. Both the functors and their operators
///   may be templatized, as a way to circumvent the limits on partial template
///   specializations imposed by C++
/// * the kernel params, particle data, neighbor data etc are also complex templatized
///   structures; you can work around this when having to declare the arguments to
///   the functor operators by using generic typenames FP, P, N, OP, ON
///   (for Forces Params, Particle, Neighbor, Output for Particle, Output from Neighbor)

/// The file is thus structured:
/// * a set of auxiliary functions, which are used later on to initialize
///   const members of structures in one go; these are needed
/// * particle data structures and output variables
/// * neighbor data structures and output variables
/// * functors for the computation of forces contributions
/// * functors for post-processing and saving
/// * global (shared) variables and their functors
/// * the actual forcesDevice kernel

/*
 * Auxiliary functions, needed to initialize const members in one go
 */

/// Precompute pressure contribution to the momentum equation.
/// Two versions are available, one in the KEPS viscosity case,
/// and a generic one

/// Precompute pressure contribution to momentum equation
/*! This function precomputes the pressure contribution to the
 * 	momentum equation according to the chosen SPH formulation.
 *
 * 	\tparam sph_formulation : SPH formulation used
 *
 *	\return : pressure contribution
 */
 //@{
template<SPHFormulation sph_formulation>
__device__ __forceinline__
float
precalc_pressure(const float rho, 	/// [in] particle density \f$\rho/f$
		particleinfo const& info, 	/// [in] particle info (used for fluid number)
		const float keps_k);		/// [in] particle \f$\kappaf$

/// <tt>SPH1</tt> specialisation of the #precalc_pressure with \f$\kappa - \epsilon\f$
/*! When using SPH formulation 1 with \f$\kappa - \epsilon\f$, the precomputed pressure
* contribution for the current particle is \f$\frac{P}{\rho^2} + \frac{2}{3} \frac{\kappa}{\rho}\f$.
*/
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F1>(const float rho, particleinfo const& info, const float keps_k)
{
	return (P(rho, fluid_num(info)) + 2.0f*keps_k/rho/3.0f)/(rho*rho);
}

/// <tt>SPH2</tt> specialisation of the #precalc_pressure with \f$ \kappa - \epsilon \f$
/*! When using SPH formulation 2 with \f$ \kappa - \epsilon \f$, the precomputed pressure
* contribution for the current particle is \f$ \frac{P} + \frac{2}{3} \kappa \rho \f$.
*/
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F2>(const float rho, particleinfo const& info, const float keps_k)
{
	return P(rho, fluid_num(info)) + 2.0f*keps_k/rho/3.0f;
}

template<SPHFormulation sph_formulation>
__device__ __forceinline__
float
precalc_pressure(const float rho,
		particleinfo const& info);

/// <tt>SPH1</tt> specialisation of #precalc_pressure
/*! When using SPH formulation 1, the precomputed pressure contribution
*   for the current particle is \f$ \frac{P}{\rho^2} \f$.
*/
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F1>(const float rho, particleinfo const& info)
{
	return P(rho, fluid_num(info))/(rho*rho);
}

/// <tt>SPH2</tt> specialisation of the #precalc_pressure template
/*! When using SPH formulation 2, the precomputed pressure contribution
*   for the current particle is just \f$ P \f$.
*/
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_F2>(const float rho, particleinfo const& info)
{
	return P(rho, fluid_num(info));
}

/// <tt>SPH_GRENIER</tt> specialisation of the #precalc_pressure template
/*! When using Grenier's SPH formulation, the precomputed pressure contribution
*   for the current particle is \f$ \frac{P}{\sigma} \f$. The division by \f$ \sigma \f$
*   will be done in p_precalc_particle_data
*/
template<>
__device__ __forceinline__
float
precalc_pressure<SPH_GRENIER>(const float rho, particleinfo const& info)
{
	return P(rho, fluid_num(info));
}
//}@

/*
 * Particle data
 */

// The amount and type of particle data retrieved for the current particle
// being processed and for the neighbor particle depend on a variety of factors,
// including SPH formulation, boundary type, viscosity etc, but also the
// particle type (fluid, object, boundary, vertex). We use a conditional struct
// assembly mechanism similar to the one seen in src/forces_params.h

// data used for all particles
struct common_particle_data
{
	const	uint	index;
	particleinfo	const& info;
	float4	const&	pos;
	const	int3	gridPos;

	__device__ __forceinline__
	common_particle_data(const uint _index, float4 const& _pos, particleinfo const& _info, hashKey const* __restrict__ hash) :
		index(_index),
		info(_info),
		pos(_pos),
		gridPos(calcGridPosFromParticleHash(hash[index]))
	{}
};

// data used for all particles in finalize
struct common_finalize_particle_data
{
	const	uint	index;
	particleinfo	const& info;
	float4	const&	pos;
	float4	const&	vel;
	const	int3	gridPos;

	__device__ __forceinline__
	common_finalize_particle_data(const uint _index, float4 const& _pos, float4 const& _vel,
			particleinfo const& _info, hashKey const* hash) :
		index(_index),
		info(_info),
		pos(_pos),
		vel(_vel),
		gridPos(calcGridPosFromParticleHash(hash[index]))
	{}
};

// data used only for objects
struct rb_particle_data
{
	const	uint	rbindex;

	__device__ __forceinline__
	//rb_particle_data(particleinfo const& info) : rbindex(object(info) != 0 ? ((int)id(info)) + d_rbstartindex[object(info)-1] : UINT_MAX)
	rb_particle_data(particleinfo const& info) : rbindex( ((int)id(info)) + d_rbstartindex[object(info)] )
	{}
};

// velocity and density used for:
// * fluid particles
// * vertex particles if KEPSVISC
// also includes local speed of sound
struct vel_particle_data
{
	const	float4	vel;
	const	float	sspeed;

	__device__ __forceinline__
	vel_particle_data(const uint _index, particleinfo const& _info) :
		vel(tex1Dfetch(velTex, _index)),
		sspeed(soundSpeed(vel.w, fluid_num(_info)))
	{}

	template<typename FP> /* templatized over the kernel input params */
	__device__ __forceinline__
	vel_particle_data(FP const& params, const uint _index, particleinfo const& _info) :
		vel(params.velArray[_index]),
		sspeed(soundSpeed(vel.w, fluid_num(_info)))
	{}
};

struct eulerVel_particle_data
{
	const	float4	eulerVel;

	__device__ __forceinline__
	eulerVel_particle_data(const uint _index) :
		eulerVel(tex1Dfetch(eulerVelTex, _index))
	{}
};

struct volume_particle_data
{
	const	float	volume;

	__device__ __forceinline__
	volume_particle_data(const uint index,
		volume_forces_params const& params) :
		volume(params.volArray[index].w)
	{}
};

// data used for SPH_GRENIER
struct grenier_particle_data
{
	const	float	sigma;

	__device__ __forceinline__
	grenier_particle_data(const uint index,
		grenier_forces_params const& params) :
		sigma(params.sigmaArray[index])
	{}
};

// data used for SPH_GRENIER in finalize forces
struct grenier_finalize_particle_data
{
	const	float	sigma;

	__device__ __forceinline__
	grenier_finalize_particle_data(const uint index,
		grenier_finalize_forces_params const& params) :
		sigma(params.sigmaArray[index])
	{}
};

// data used for SA_BOUNDARY
struct sa_boundary_particle_data
{
	// does this particle want to (re)compute gamma? see logic below
	// this is used by vertex particles only
	bool	computeGamma;

	// oldGGam would hold the previous value of gamma (in .w) and its gradient (in .xyz).
	// oldGGam is used in case of vertex particles to compute the solid angle of vertex particles.
	// For fluid particles it is used in case the particle is too close to a wall
	const	float4	oldGGam;

	// boundary element, used to compute the force on a boundary element for floating objects
	const	float4 belem;

	// For fluid particles, we always want to recompute gamma, while for vertex
	// particles we only want to recompute if we have moving boundaries or if
	// gamma itself has not been computed before, where ‘computed before’ is
	// assessed by checking if its value is less than the given epsilon

	// fluid init
	__device__ __forceinline__
	sa_boundary_particle_data(const uint index, particleinfo const& info,
		sa_boundary_forces_params const& params) :
		computeGamma(true),
		// the actual oldGGam loading: this will also set computeGamma true if
		// it was false but .w was < epsilon
		oldGGam(fetchOldGamma(index, params.epsilon, computeGamma)),
		//oldGGam(make_float4(0.0)),
		belem(BOUNDARY(info) ? tex1Dfetch(boundTex, index) : make_float4(0.0f))
	{}
};

// SPSVISC particle data
struct sps_particle_data
{
	const	symtensor3	tau;

	__device__ __forceinline__
	sps_particle_data(const uint index) : tau(fetchTau(index))
	{}
};

// KEPSVISC particle data
struct keps_particle_data
{
	// turbulent kinetic energy
	const	float	keps_k;
	// turbulent dissipation
	const	float	keps_e;
	// turbulent viscosity
	const	float	turbVisc;
	// turbulent viscosity for viscous term
	// this is 0 for vertex particles
	const	float	turbViscForViscTerm;

	__device__ __forceinline__
	keps_particle_data(const uint index, particleinfo const& info) :
		keps_k(tex1Dfetch(keps_kTex, index)),
		keps_e(tex1Dfetch(keps_eTex, index)),
		turbVisc(0.09f*keps_k*keps_k/keps_e),
		turbViscForViscTerm((FLUID(info) || (VERTEX(info) && IO_BOUNDARY(info) && !CORNER(info))) ? turbVisc : 0)
	{}
};

// Precomputed pressure contribution
// Automatic initialization of this beast is a bit messy because
// (1) we want it to be const
// (2) the initialization depends on SPH formulation and viscosity type
// (3) with KEPSVISC and SPH_GRENIER it needs one additional parameter
// (4) the value passed to the additional parameter only exists in the KEPSVISC/SPH_GRENIER case
// so the caller must be able to feed the last parameter correctly if it exsists,
// but not even try to provide it otherwise.
// The solution is to make this a templatized structure based on
// SPH formulation, plus the typename of an additional parameter, which
// will be the structure containing keps_k in the case of KEPSVISC.
// Suggestions for a better solution are welcome
template<SPHFormulation sph_formulation, typename T>
struct p_precalc_particle_data
{
	const	float	p_precalc;

	// default initializer, extra param is ignored
	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, T const&) :
		p_precalc(precalc_pressure<sph_formulation>(rho, info))
	{}
};

// Specialization for SPH_GRENIER formulation
// TODO check compatibility between SPH_GRENIER and KEPSVISC
template<>
struct p_precalc_particle_data<SPH_GRENIER, grenier_particle_data>
{
	const	float	p_precalc;

	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, grenier_particle_data const& pdata) :
		p_precalc(precalc_pressure<SPH_GRENIER>(rho, info)/pdata.sigma)
	{}
};

// specialize the initializer
template<SPHFormulation sph_formulation>
struct p_precalc_particle_data<sph_formulation, keps_particle_data>
{
	const	float	p_precalc;

	__device__ __forceinline__
	p_precalc_particle_data(const float rho, particleinfo const& info, keps_particle_data const& ke) :
		p_precalc(precalc_pressure<sph_formulation>(rho, info, ke.keps_k))
	{}
};

// KEPSVISC precalc data, used only for fluid particles
// again, turbVisc should only be actually accessed by the caller if we are with KEPSVISC,
// so we assume the caller passes us a full keps_particle_data structure
// (which they will only do in the KEPSVISC case)
struct keps_precalc_particle_data
{
	const	float	dkdt_precalc;
	const	float	dedt_precalc;

	__device__ __forceinline__
	keps_precalc_particle_data(const float rho, const uint fnum, keps_particle_data const& ke) :
		dkdt_precalc(rho*(d_visccoeff[fnum] + ke.turbVisc)),
		dedt_precalc(rho*(d_visccoeff[fnum] + ke.turbVisc/1.3f))
	{}
};

// And now we assemble them. Not all particle types require all particle data,
// but for the time being we don't optimize this far and just limit ourselves
// to conditional inclusions based on kernel specialization only, not particle type

template<KernelType _kerneltype,
	SPHFormulation _sph_formulation,
	DensityDiffusionType _densitydiffusiontype,
	BoundaryType _boundarytype,
	ViscosityType _visctype,
	flag_t _simflags,
	ParticleType _cptype,
	ParticleType _nptype>
struct forces_particle_data :
	// included unconditionally for all particles:
	common_particle_data,
	// the next is only needed for PT_OBJECT, which in fact need no other data
	rb_particle_data,
	// vel included unconditionally for all particles, even though
	// PT_VERTEX only use them for KEPSVISC, and
	// PT_OBJECT don't use them
	vel_particle_data,
	COND_STRUCT(_sph_formulation == SPH_GRENIER &&
		(_densitydiffusiontype == COLAGROSSI), volume_particle_data),
	COND_STRUCT(_sph_formulation == SPH_GRENIER, grenier_particle_data),
	// eulerian velocity only used in case of keps or with open boundaries
	COND_STRUCT(_boundarytype == SA_BOUNDARY && _cptype != _nptype
			&& (_visctype == KEPSVISC || _simflags & ENABLE_INLET_OUTLET) , // TODO this only works for SA_BOUNDARY atm
		eulerVel_particle_data),
	// SA_BOUNDARY data (always needed by PT_VERTEX, since they only obviously
	// appear with SA_BOUNDARY)
	COND_STRUCT(_boundarytype == SA_BOUNDARY && _cptype != _nptype,
		sa_boundary_particle_data),
	// KEPSVISC data, needed by both PT_FLUID and PT_VERTEX
	COND_STRUCT(_visctype == KEPSVISC,
		keps_particle_data),
	// everything else is just for PT_FLUID
	COND_STRUCT(_visctype == SPSVISC,
		sps_particle_data),
	// to see why this is so messy, see definition of p_precalc_particle_data
	p_precalc_particle_data<_sph_formulation,
		typename conditional<_sph_formulation == SPH_GRENIER,
		grenier_particle_data, typename COND_STRUCT(_visctype == KEPSVISC, keps_particle_data)
	>::type >,
	COND_STRUCT(_visctype == KEPSVISC,
		keps_precalc_particle_data)
{
	static const KernelType kerneltype = _kerneltype;
	static const SPHFormulation sph_formulation = _sph_formulation;
	static const DensityDiffusionType densitydiffusiontype = _densitydiffusiontype;
	static const BoundaryType boundarytype = _boundarytype;
	static const ViscosityType visctype = _visctype;
	static const flag_t simflags = _simflags;
	static const ParticleType cptype = _cptype;
	static const ParticleType nptype = _nptype;

	// shorthand for the type of the forces params
	typedef forces_params<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, cptype, nptype> params_t;

	ParticleType	ptype;

	// determine specialization automatically based on info and params
	__device__ __forceinline__
	forces_particle_data(const uint _index, float4 const& _pos, particleinfo const& _info,
		params_t const& params) :
		common_particle_data(_index, _pos, _info, params.particleHash),
		rb_particle_data(_info),
		vel_particle_data(_index, _info),
		COND_STRUCT(_sph_formulation == SPH_GRENIER &&
			(_densitydiffusiontype == COLAGROSSI), volume_particle_data)
			(_index, params),
		COND_STRUCT(sph_formulation == SPH_GRENIER, grenier_particle_data)(_index, params),
		COND_STRUCT(boundarytype == SA_BOUNDARY && cptype != nptype &&
				(visctype == KEPSVISC || simflags & ENABLE_INLET_OUTLET),
			eulerVel_particle_data)(_index),
		COND_STRUCT(boundarytype == SA_BOUNDARY && cptype != nptype,
			sa_boundary_particle_data)(_index, _info, params),
		COND_STRUCT(visctype == KEPSVISC,
			keps_particle_data)(_index, _info),
		COND_STRUCT(visctype == SPSVISC,
			sps_particle_data)(_index),
		p_precalc_particle_data<sph_formulation,
			typename conditional<sph_formulation == SPH_GRENIER,
			grenier_particle_data, typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)
		>::type >(vel.w, _info, *this),
		COND_STRUCT(visctype == KEPSVISC, keps_precalc_particle_data)(vel.w, fluid_num(_info), *this),
		ptype(PART_TYPE(_info))
	{}
};

struct sa_finalize_particle_data
{
	// x,y,z contains the gradient of gamma, w gamma itself
	const float4	gGam;
	const float4	oldGGam;

	__device__ __forceinline__
	sa_finalize_particle_data(const uint index,
			sa_finalize_forces_params const& params) :
		gGam(params.gGam[index]),
		oldGGam(params.oldGGam[index])
	{}
};

template<SPHFormulation _sph_formulation,
	BoundaryType _boundarytype,
	ViscosityType _visctype,
	flag_t _simflags>
struct finalize_forces_particle_data :
	// included unconditionally for all particles:
	common_finalize_particle_data,
	// the next is only needed for PT_OBJECT, which in fact need no other data
	rb_particle_data,
	COND_STRUCT(_sph_formulation == SPH_GRENIER, grenier_finalize_particle_data),
	COND_STRUCT(_boundarytype == SA_BOUNDARY, sa_finalize_particle_data)
	{
	static const SPHFormulation sph_formulation = _sph_formulation;
	static const BoundaryType boundarytype = _boundarytype;
	static const ViscosityType visctype = _visctype;
	static const flag_t simflags = _simflags;

	// shorthand for the type of the forces params
	typedef finalize_forces_params<sph_formulation, boundarytype, visctype, simflags> params_t;

	ParticleType	ptype;

	// determine specialization automatically based on info and params
	__device__ __forceinline__
	finalize_forces_particle_data(const uint _index, float4 const& _pos, particleinfo const& _info,
		params_t const& params) :
		common_finalize_particle_data(_index, _pos, params.velArray[_index], _info, params.particleHash),
		rb_particle_data(_info),
		COND_STRUCT(sph_formulation == SPH_GRENIER, grenier_finalize_particle_data)(_index, params),
		COND_STRUCT(boundarytype == SA_BOUNDARY, sa_finalize_particle_data)(_index, params)
		{}
};

/// Similarly for the output variables

// common
struct common_particle_output
{
	float4	force;

	template<typename FP>
	__device__ __forceinline__
	common_particle_output(FP const& params, const uint index) :
		force(params.forces[index])
	{}
};

// SA_BOUNDARY
struct sa_boundary_particle_output
{
	// x,y,z contains the gradient of gamma, w gamma itself
	float4	gGam;
	// time derivative of gamma
	float	dgamdt;

	template<typename FP>
	__device__ __forceinline__
	sa_boundary_particle_output(FP const& params, const uint index) :
		gGam(make_float4(0, 0, 0, 1)),
		dgamdt(params.dgamdt[index])
	{}
};

// CFL condition for gamma integration when using SA_BOUNDARY
struct gamma_cfl_particle_output
{
	// max value of \nabla \gamma_{as} \cdot {v_{as}, v_a - u_s, u_s + v_s} for cfl condition
	float	gammaCfl;

	__device__ __forceinline__
	gamma_cfl_particle_output() :
		gammaCfl(0.0f)
	{}

	template<typename FP>
	__device__ __forceinline__
	gamma_cfl_particle_output(FP const& params, const uint index) :
		gammaCfl(params.cfl_gamma[index])
	{}
};

template<typename OP>
using has_gammaCfl = typename std::is_base_of<gamma_cfl_particle_output, OP>;

template<typename OP, typename T=void>
using enable_if_gammaCfl = typename std::enable_if<has_gammaCfl<OP>::value, T>::type;
template<typename OP, typename T=void>
using enable_if_not_gammaCfl = typename std::enable_if<!has_gammaCfl<OP>::value, T>::type;


// KEPSVISC
struct keps_particle_output
{
	float3	dvx;
	float3	dvy;
	float3	dvz;

	float	diff_term_k;
	float	diff_term_e;
	float	ce2yap;

	__device__ __forceinline__
	keps_particle_output()
	{
		dvx = dvy = dvz = make_float3(0.0f);
		diff_term_k = diff_term_e = 0;
		ce2yap = 1.92f;
	}
};

// XSPH
struct xsph_particle_output
{
	float3	mean_vel;

	__device__ __forceinline__
	xsph_particle_output() : mean_vel(make_float3(0.0f))
	{}
};

struct internal_energy_particle_output
{
	float DEDt; // derivative of the internal energy with respect to time

	__device__ __forceinline__
	internal_energy_particle_output() : DEDt(0.0f)
	{}
};

template<BoundaryType _boundarytype,
	ViscosityType _visctype,
	flag_t _simflags,
	ParticleType cptype,
	ParticleType nptype>
struct forces_particle_output :
	common_particle_output,
	// TODO FIXME KEPSVISC currently depends on SA_BOUNDARY (see .e.g viscous_fixup<KEPSVISC>),
	// but there is no way to prevent it from being selected with other boundary conditions.
	// When this is implemented, the || visctype == KEPSVISC should be removed
	COND_STRUCT(_boundarytype == SA_BOUNDARY || _visctype == KEPSVISC, sa_boundary_particle_output),
	COND_STRUCT(_boundarytype == SA_BOUNDARY && USING_DYNAMIC_GAMMA(_simflags) && (_simflags & ENABLE_DTADAPT) &&
		cptype == PT_FLUID && nptype == PT_BOUNDARY,
		gamma_cfl_particle_output),
	COND_STRUCT(_visctype == KEPSVISC, keps_particle_output),
	COND_STRUCT(_simflags & ENABLE_XSPH, xsph_particle_output),
	COND_STRUCT(_simflags & ENABLE_INTERNAL_ENERGY, internal_energy_particle_output)
{
	static const BoundaryType boundarytype = _boundarytype;
	static const ViscosityType visctype = _visctype;
	static const flag_t simflags = _simflags;

	template<typename FP>
	__device__ __forceinline__
	forces_particle_output(FP const& params, const uint index) :
		common_particle_output(params, index),
		// TODO FIXME see above
		COND_STRUCT(boundarytype == SA_BOUNDARY || visctype == KEPSVISC, sa_boundary_particle_output)(params, index),
		COND_STRUCT(boundarytype == SA_BOUNDARY && USING_DYNAMIC_GAMMA(simflags) && (simflags & ENABLE_DTADAPT) &&
			cptype == PT_FLUID && nptype == PT_BOUNDARY,
			gamma_cfl_particle_output)(),
		COND_STRUCT(visctype == KEPSVISC, keps_particle_output)(),
		COND_STRUCT(simflags & ENABLE_XSPH, xsph_particle_output)(),
		COND_STRUCT(simflags & ENABLE_INTERNAL_ENERGY, internal_energy_particle_output)()
	{}
};

// SA_BOUNDARY
struct sa_finalize_particle_output
{
	float	dgamdt;

	template<typename FP>
	__device__ __forceinline__
	sa_finalize_particle_output(FP const& params, const uint index) :
		dgamdt(params.dgamdt[index])
	{}
};

template<BoundaryType _boundarytype, flag_t _simflags>
struct finalize_particle_output :
	common_particle_output,
	COND_STRUCT(_boundarytype == SA_BOUNDARY, sa_finalize_particle_output),
	COND_STRUCT(_boundarytype == SA_BOUNDARY && USING_DYNAMIC_GAMMA(_simflags) && (_simflags & ENABLE_DTADAPT),
		gamma_cfl_particle_output)
{
	template<typename FP>
	__device__ __forceinline__
	finalize_particle_output(FP const& params, const uint index) :
		common_particle_output(params, index),
		COND_STRUCT(_boundarytype == SA_BOUNDARY, sa_finalize_particle_output)(params, index),
		COND_STRUCT(_boundarytype == SA_BOUNDARY && USING_DYNAMIC_GAMMA(_simflags) && (_simflags & ENABLE_DTADAPT),
			gamma_cfl_particle_output)(params, index)
	{}
};

/*
 * Neib data
 */

// Just like for particle data, we collect neib data into appropriate structures

/* We may fetch velocity either from the kernel params (if there is a velArray),
   or from the velTex texture (otherwise). We abstract this selection in the following pair
   of specialized functions. We use the C++17 bool_constant alias */

#if __cplusplus >= 201703L
using std::bool_constant;
#else
template<bool B>
using bool_constant = std::integral_constant<bool, B>;
#endif

/* By default, assume the velArray member is not present. We will specialize this in the true case
 * by playing on the second, implicit parameter */
template<typename FP, typename = std::true_type> struct has_velArray : std::false_type {};
/* Specialization that due to SFINAE will only be triggered when FP::velArray is a valid expression */
template<typename FP> struct has_velArray<FP, bool_constant<sizeof(FP::velArray)>> : std::true_type {};

template<typename FP, typename T>
using enable_with_velArray = typename std::enable_if<has_velArray<FP>::value, T>::type;
template<typename FP, typename T>
using enable_without_velArray = typename std::enable_if<!has_velArray<FP>::value, T>::type;

template<typename FP>
__device__ __forceinline__
enable_with_velArray<FP, float4>
fetchVel(FP params, uint index)
{
	return params.velArray[index];
}

template<typename FP>
__device__ __forceinline__
enable_without_velArray<FP, float4>
fetchVel(FP params, uint index)
{
	return tex1Dfetch(velTex, index);
}


// data used fo all neibs
struct common_neib_data
{
	particleinfo	const& info;
	// relPos holds the distance vector in .xyz and the neib mass in .w
	float4	const&	relPos;
	const	float	r;

	// relVel holds the relative velocity in .xyz and the neib density in .w
	const	float4	relVel;
	const	float	vel_dot_pos;
	// norm of the gradient of the kernel
	const	float	f;
	// kernel value
	const	float	w;
	// local speed of sound
	const	float sspeed;

	/* The constructor is templatized on the particle data type and on the
	   kernel params type */
	template<typename Pt, typename FP>
	__device__ __forceinline__
	common_neib_data(Pt const& pdata, FP const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		info(_info), relPos(_relPos), r(_r),
		relVel(as_float3(pdata.vel) - fetchVel(params, _index)),
		vel_dot_pos(dot3(relVel, relPos)),
		f(F<FP::kerneltype>(r, params.slength)),
		w(W<FP::kerneltype>(r, params.slength)),
		sspeed(soundSpeed(relVel.w, fluid_num(_info)))
	{}
};

struct sa_boundary_neib_data
{
	const uint index;

	const	float4	belem;
	const	float3&	normal_s;
	// distance of particle to boundary element along the normal
	const	float	r_as; // r_as as used by ptype == PT_FLUID, r_es as used by ptype == PT_VERTEX

	template<typename Pt, typename FP>
	__device__ __forceinline__
	sa_boundary_neib_data(Pt const& pdata, FP const& params,
		const uint _index, float4 const& _relPos) :
		index(_index),
		belem(tex1Dfetch(boundTex, index)),
		normal_s(as_float3(belem)),
		r_as(fmax(fabs(dot(as_float3(_relPos), normal_s)), params.deltap))
	{}
};

struct eulerVel_neib_data
{
	const float4 relEulerVel;

	template<typename Pt>
	__device__ __forceinline__
	eulerVel_neib_data(Pt const& pdata, const uint _index, const particleinfo _info) :
		relEulerVel(as_float3(pdata.eulerVel) - tex1Dfetch(eulerVelTex, _index))
	{}
};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags,
	ParticleType cptype,
	ParticleType nptype>
struct forces_neib_data :
	common_neib_data,
	COND_STRUCT(sph_formulation == SPH_GRENIER &&
		(densitydiffusiontype == COLAGROSSI), volume_particle_data),
	COND_STRUCT(sph_formulation == SPH_GRENIER, grenier_particle_data),
	COND_STRUCT(boundarytype == SA_BOUNDARY && cptype != nptype,
		sa_boundary_neib_data),
	// relative eulerian velocity
	COND_STRUCT(boundarytype == SA_BOUNDARY && cptype != nptype &&
			(visctype == KEPSVISC || simflags & ENABLE_INLET_OUTLET),
		eulerVel_neib_data),
	// these are the same as the particle data
	COND_STRUCT(visctype == KEPSVISC, keps_particle_data),
	// precalculated pressure
	p_precalc_particle_data<sph_formulation,
		typename conditional<sph_formulation == SPH_GRENIER,
		grenier_particle_data, typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)
	>::type >,
	COND_STRUCT(visctype == SPSVISC, sps_particle_data)
{
	// shortcut typedefs
	typedef
		typename COND_STRUCT(boundarytype == SA_BOUNDARY && cptype != nptype,
			sa_boundary_neib_data)
		_sa_boundary_neib_data;
	typedef
		typename COND_STRUCT(boundarytype == SA_BOUNDARY && cptype != nptype &&
				(visctype == KEPSVISC || simflags & ENABLE_INLET_OUTLET),
			eulerVel_neib_data)
		_eulerVel_neib_data;

	ParticleType	ntype;

	/* The constructor is templatized on the particle data type and on the
	   kernel params type */
	template<typename Pt, typename FP>
	__device__ __forceinline__
	forces_neib_data(Pt const& pdata, FP const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		common_neib_data(pdata, params, _index, _info, _relPos, _r),
		COND_STRUCT(sph_formulation == SPH_GRENIER &&
			(densitydiffusiontype == COLAGROSSI), volume_particle_data)
			(_index, params),
		COND_STRUCT(sph_formulation == SPH_GRENIER, grenier_particle_data)(_index, params),
		_sa_boundary_neib_data(pdata, params, _index, _relPos),
		_eulerVel_neib_data(pdata, _index, _info),
		COND_STRUCT(visctype == KEPSVISC, keps_particle_data)(_index, _info),
		COND_STRUCT(visctype == SPSVISC, sps_particle_data)(_index),
		p_precalc_particle_data<sph_formulation,
			typename conditional<sph_formulation == SPH_GRENIER,
			grenier_particle_data, typename COND_STRUCT(visctype == KEPSVISC, keps_particle_data)
		>::type >(this->relVel.w, _info, *this),
		ntype(PART_TYPE(_info))
	{}
};

/// And finally the neib contribution to the current particle forces
struct common_neib_output
{
	// acceleration
	float3	DvDt;
	// density derivative
	float	DrDt;

	__device__ __forceinline__
	common_neib_output() :
		DvDt(make_float3(0.0f)),
		DrDt(0.0f)
	{}
};

struct ggam_neib_output
{
	// ggamAS as used by ptype == PT_FLUID, gamES as used by ptype == PT_VERTEX
	float	ggamAS;

	__device__ __forceinline__
	ggam_neib_output() :
		ggamAS(0.0f)
	{ }
};

struct sa_boundary_neib_output : ggam_neib_output
{
	float	DgamDt;

	__device__ __forceinline__
	sa_boundary_neib_output() :
		ggam_neib_output(),
		DgamDt(0.0f)
	{ }
};

template<BoundaryType boundarytype>
struct forces_neib_output :
	common_neib_output,
	COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_output)
{
	__device__ __forceinline__
	forces_neib_output() :
		common_neib_output(),
		COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_output)()
	{}
};

/*
 * A lot of parts of the forces kernel behave very differently based on some template parameters.
 * We isolate this behavior in template functions defined (and specialized) here.
 * TODO FIXME the syntax of these functors could be OH SO MUCH CLEANER if we could use C++11 ...
 */

/// The next set of functions check  if the given particle (pdata) should skip
/// traversing the neib list, and define the actions to be taken when skipping.
/// Since we need partial specialization, they cannot be actual functions.
template<BoundaryType boundarytype,
	ParticleType cptype,
	ParticleType nptype>
struct skip_neiblist
{
	/// check if the given particle must skip the neiblist traversal
	template<typename FP, typename P>
	__device__ __forceinline__
	bool check(FP const& params, P const& pdata)
	{
		return false; // default, don't skip
	}

	/// do anything that is needed to actually skip the neiblist traversal
	template<typename P, typename OP>
	__device__ __forceinline__
	void prepare(P const& pdata, OP &pout)
	{ /* do nothing by default */ }

};

template<ParticleType nptype>
struct skip_neiblist<SA_BOUNDARY, PT_VERTEX, nptype>
{
	template<typename FP, typename P>
	__device__ __forceinline__
	bool check(FP const& params, P const& pdata)
	{
		// if the vertex needs to compute gamma, then we can't skip
		if (pdata.computeGamma)
			return false;
		// in case of k-epsilon we need to compute the viscous force acting on the vertex
		else if (FP::visctype == KEPSVISC)
			return false;
		// in case of IO and pressure outlet we need to compute the water level
		else if (FP::simflags & ENABLE_INLET_OUTLET && IO_BOUNDARY(pdata.info) && PRES_IO(pdata.info))
			return false;
		// if none of the above matches, then we can skip the neighbour loop
		else
			return true;
	}

	template<typename P, typename OP>
	__device__ __forceinline__
	void prepare(P const& pdata, OP &pout)
	{
		// FIXME currently we can expect it to be a vertex particle, and this is what
		// we need to do, but in the future there might be other cases too
		pout.gGam = pdata.oldGGam;
	}
};

/*
 * Functors to compute neighbor contributions. Template structs with a single
 * static method (`with`) which takes params, pdata, ndata as const& input,
 * and pout, nout as & output. The method may also return something.
 * The method should be a template method based on the typenames of its arguments
 * (which would otherwise be too complex to specify, and it's not even necessary
 *  since template functions auto-match their arguments), so any specialization
 * based on the struct template parameter(s) will have two template<> specifications:
 * the first one for the struct, and the second (unchanged from the declaration)
 * for the method.
 */

/// A functor that computes the new gamma. Obviously does something
/// only in the case of SA_BOUNDARY
template<BoundaryType, ParticleType cptype, bool usedynamicgamma>
struct compute_gamma {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<ParticleType cptype>
struct compute_gamma<SA_BOUNDARY, cptype, true> {
	// compute the contribution to the gamma gradient from a single neighbor
	template<typename FP, typename P, typename N>
	__device__ __forceinline__
	static float
	gradient(FP const& params, P const& pdata, N const& ndata)
	{
		// local coordinate system for relative positions to vertices
		uint j = 0;
		// Get index j for which n_s is minimal
		if (fabs(ndata.belem.x) > fabs(ndata.belem.y))
			j = 1;
		if ((1-j)*fabs(ndata.belem.x) + j*fabs(ndata.belem.y) > fabs(ndata.belem.z))
			j = 2;

		// compute the first coordinate which is a 2-D rotated version of the normal
		const float3 coord1 = normalize(make_float3(
					// switch over j to give: 0 -> (0, z, -y); 1 -> (-z, 0, x); 2 -> (y, -x, 0)
					-((j==1)*ndata.belem.z) +  (j == 2)*ndata.belem.y , // -z if j == 1, y if j == 2
					(j==0)*ndata.belem.z  - ((j == 2)*ndata.belem.x), // z if j == 0, -x if j == 2
					-((j==0)*ndata.belem.y) +  (j == 1)*ndata.belem.x // -y if j == 0, x if j == 1
					));
		// the second coordinate is the cross product between the normal and the first coordinate
		const float3 coord2 = cross(as_float3(ndata.belem), coord1);

		// relative positions of vertices with respect to the segment
		const float3 qva = -(params.vertPos0[ndata.index].x*coord1 + params.vertPos0[ndata.index].y*coord2)/params.slength; // e.g. v0 = r_{v0} - r_s
		const float3 qvb = -(params.vertPos1[ndata.index].x*coord1 + params.vertPos1[ndata.index].y*coord2)/params.slength;
		const float3 qvc = -(params.vertPos2[ndata.index].x*coord1 + params.vertPos2[ndata.index].y*coord2)/params.slength;
		float3 q_vb[3] = {qva, qvb, qvc};
		const float3 q = as_float3(ndata.relPos)/params.slength;

		return gradGamma<FP::kerneltype>(params.slength, q, q_vb, as_float3(ndata.belem));
	}

	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		if (!pdata.computeGamma && VERTEX(pdata.info) && IO_BOUNDARY(pdata.info) && !VEL_IO(pdata.info))
			return;

		// compute nout.ggamAS
		nout.ggamAS = gradient(params, pdata, ndata);

		// TODO: we need to output grad gamma only when using olgGGam (that is grad gamma from the previous step).
		// Check when olgGGam is REALLY necessary.
		pout.gGam.x += nout.ggamAS*ndata.belem.x;
		pout.gGam.y += nout.ggamAS*ndata.belem.y;
		pout.gGam.z += nout.ggamAS*ndata.belem.z;
	}
};

template<ParticleType cptype>
struct compute_gamma<SA_BOUNDARY, cptype, false> {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		if (!pdata.computeGamma && VERTEX(pdata.info) && IO_BOUNDARY(pdata.info) && !VEL_IO(pdata.info))
			return;

		// local coordinate system for relative positions to vertices
		uint j = 0;
		// Get index j for which n_s is minimal
		if (fabs(ndata.belem.x) > fabs(ndata.belem.y))
			j = 1;
		if ((1-j)*fabs(ndata.belem.x) + j*fabs(ndata.belem.y) > fabs(ndata.belem.z))
			j = 2;

		// compute the first coordinate which is a 2-D rotated version of the normal
		const float3 coord1 = normalize(make_float3(
					// switch over j to give: 0 -> (0, z, -y); 1 -> (-z, 0, x); 2 -> (y, -x, 0)
					-((j==1)*ndata.belem.z) +  (j == 2)*ndata.belem.y , // -z if j == 1, y if j == 2
					(j==0)*ndata.belem.z  - ((j == 2)*ndata.belem.x), // z if j == 0, -x if j == 2
					-((j==0)*ndata.belem.y) +  (j == 1)*ndata.belem.x // -y if j == 0, x if j == 1
					));
		// the second coordinate is the cross product between the normal and the first coordinate
		const float3 coord2 = cross(as_float3(ndata.belem), coord1);

		// relative positions of vertices with respect to the segment
		const float3 qva = -(params.vertPos0[ndata.index].x*coord1 + params.vertPos0[ndata.index].y*coord2)/params.slength; // e.g. v0 = r_{v0} - r_s
		const float3 qvb = -(params.vertPos1[ndata.index].x*coord1 + params.vertPos1[ndata.index].y*coord2)/params.slength;
		const float3 qvc = -(params.vertPos2[ndata.index].x*coord1 + params.vertPos2[ndata.index].y*coord2)/params.slength;
		float3 q_vb[3] = {qva, qvb, qvc};
		const float3 q = as_float3(ndata.relPos)/params.slength;

		nout.ggamAS = gradGamma<FP::kerneltype>(params.slength, q, q_vb, as_float3(ndata.belem));
		// TODO: we need to output grad gamma only when using olgGGam (that is grad gamma from the previous step).
		// Check when olgGGam is REALLY necessary.
		pout.gGam.x += nout.ggamAS*ndata.belem.x;
		pout.gGam.y += nout.ggamAS*ndata.belem.y;
		pout.gGam.z += nout.ggamAS*ndata.belem.z;

		const float gamma_as = Gamma<FP::kerneltype, cptype>(params.slength, q, q_vb, as_float3(ndata.belem),
					as_float3(pdata.oldGGam), params.epsilon);
		pout.gGam.w -= gamma_as;
	}
};

// A functor to compute the gamma CFL
template<bool needs_cfl, bool ioBoundary>
struct compute_gamma_cfl {
	template<typename FP, typename OP, typename P, typename N, typename ON>
	__device__ __forceinline__
	static void with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

// Specialization of compute_gamma_cfl in the case of dynamic gamma and no IO
template<>
template<typename FP, typename OP, typename P, typename N, typename ON>
__device__ __forceinline__ void
compute_gamma_cfl<true, false>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// compute cfl condition for gamma, no IO here, so it's only |gradGamma_{as}| * |(n . (v_a - v_s))|
	pout.gammaCfl = fmax( pout.gammaCfl, nout.ggamAS*fmax(
			// n . (v_a - v_s)
			fabs(dot3(ndata.belem, ndata.relVel)), fmax(
			// n . (v_a - u_s)
			fabs(dot3(ndata.belem, pdata.vel)),
			// n . (v_s + u_s)
			fabs(dot3(ndata.belem, pdata.vel - ndata.relVel))
			))
		);
}

// Specialization of compute_gamma_cfl in the case of dynamic gamma and IO
template<>
template<typename FP, typename OP, typename P, typename N, typename ON>
__device__ __forceinline__
void compute_gamma_cfl<true, true>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// non-IO contribution
	compute_gamma_cfl<true, false>::with(params, pdata, ndata, pout, nout);

	// IO contribution, taking relEulerVel into account
	// compute cfl condition for gamma, always |gradGamma_{as}| * |(n . velocity)|
	pout.gammaCfl = fmax(pout.gammaCfl, nout.ggamAS*fmax(
		// n . (v_a - u_s)
		fabs(dot3(ndata.belem, pdata.vel+ndata.relEulerVel)),
		// n . (v_s + u_s)
		fabs(dot3(ndata.belem, -ndata.relVel+pdata.vel-ndata.relEulerVel)) ));
}


// A functor that helps to compute the influence of eulerian velocities onto the governing equations
template<bool inoutBoundaries>
struct compute_gamma_dot_io {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_gamma_dot_io<true>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	nout.DgamDt -= nout.ggamAS*dot3(ndata.belem, ndata.relEulerVel-pdata.eulerVel);
}

// A functor that computes D gamma / Dt
template<bool dynamic_gamma>
struct
compute_gamma_dot
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{ /* do nothing */ }
};

// Compute D gamma / Dt in the case of dynamic gamma
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__
void
compute_gamma_dot<true>::with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
{
	// boundary term of div(v)
	nout.DgamDt += dot3(ndata.relVel, ndata.belem)*nout.ggamAS;

	compute_gamma_dot_io<FP::simflags & ENABLE_INLET_OUTLET>::with(params, pdata, ndata, pout, nout);

	compute_gamma_cfl<
		has_gammaCfl<OP>::value, /* needs_cfl */
		(FP::simflags & ENABLE_INLET_OUTLET) /* ioBoundary */
		>::with(params, pdata, ndata, pout, nout);

	pout.dgamdt += nout.DgamDt;
}


/// A functor that helps to compute the influence of eulerian velocities onto the governing equations
template<bool inoutBoundaries>
struct compute_euler_contributions {
	// boundary term
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	boundary_term(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }

	// volumic term
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	volumic_term(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_euler_contributions<true>::boundary_term(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	nout.DrDt -= dot3(ndata.relEulerVel, ndata.belem)*nout.ggamAS;
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_euler_contributions<true>::volumic_term(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// this should be divided by the neib density (ndata.relVel.w),
	// but would be multiplied by the same quantity in SPH_F1 formulation,
	// so we delegate the division to the caller, when needed
	// TODO this should be handled more intelligently, might require some
	// restructuring
	nout.DrDt += ndata.relPos.w*dot3(ndata.relEulerVel, ndata.relPos)*ndata.f;
}

/// A functor that computes the ratio of the volumes of two particles
/// either as rho_N/rho_P (if the volume is not available) or as vol_P/vol_N
/// (if the volume is available, e.g. with SPH_GRENIER)
template<bool has_volume>
struct volume_ratio {
	template<typename P, typename N>
	__device__ __forceinline__
	static float
	with(P const& pdata, N const& ndata) {
		return ndata.relVel.w/pdata.vel.w;
	}
};

/* With Grenier we  use the volume directly */
template<>
template<typename P, typename N>
__device__ __forceinline__
float
volume_ratio<true>::with(P const& pdata, N const& ndata) {
	return pdata.volume/ndata.volume;
}

/// A functor that computes a density diffusion term.
/// There are three different options implemented at the moment, Ferrari, Brezzi and Colagrossi
template<DensityDiffusionType densitydiffusiontype,
		BoundaryType boundarytype,
		ParticleType cptype,
		ParticleType nptype>
struct compute_density_diffusion {
	template<typename FP, typename P, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, ON &nout)
	{ /* do nothing */ }
};

/// Diffusion term for Ferrari for fluid neighbours
/// according to Mayrhofer et al. 2013, CPC
template<BoundaryType boundarytype,
		ParticleType cptype>
struct compute_density_diffusion<FERRARI, boundarytype, cptype, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, ON &nout)
	{
		const uint fType =  fluid_num(pdata.info);
		// gravity correction for free-surface flows
		const float grav_corr = -dot(d_gravity, as_float3(ndata.relPos))*d_rho0[fType]/d_sqC0[fType];
		// actual diffusion term
		const float3 ferraricor = (ndata.r > 1e-4f*params.slength) ?
			max(pdata.sspeed, ndata.sspeed)*
			(pdata.vel.w - ndata.relVel.w + grav_corr)/pdata.vel.w/ndata.r*as_float3(ndata.relPos) :
			make_float3(0.0f);
		// adding term to D\rho/Dt, weighted with d_densityDiffCoeff (choose according to Mayrhofer et al. 2013, CPC)
		nout.DrDt += d_densityDiffCoeff*ndata.relPos.w*dot(ferraricor, as_float3(ndata.relPos))*ndata.f;
	}
};

/// Diffusion term for Ferrari for boundary neighbours in the case of semi-analytical boundaries
/// according to Mayrhofer et al. 2013, CPC
template<ParticleType cptype>
struct
compute_density_diffusion<FERRARI, SA_BOUNDARY, cptype, PT_BOUNDARY>
{
	template<typename FP, typename P, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, ON &nout)
	{
		const int fType =  fluid_num(pdata.info);
		// gravity correction for free-surface flows
		const float grav_corr = -dot(d_gravity, as_float3(ndata.relPos))*d_rho0[fType]/d_sqC0[fType];
		// actual diffusion term
		const float ferraricor = (ndata.r > 1e-4f*params.slength) ?
			max(pdata.sspeed, ndata.sspeed)*
			(pdata.vel.w - ndata.relVel.w + grav_corr)/ndata.r :
			0.0f;
		// adding term to D\rho/Dt, weighted with d_densityDiffCoeff (choose according to Mayrhofer et al. 2013, CPC)
		nout.DrDt -= d_densityDiffCoeff*ferraricor*dot3(ndata.relPos,ndata.belem)*nout.ggamAS;
	}
};

/// Diffusion term for Brezzi for fluid neighbours
template<BoundaryType boundarytype,
		ParticleType cptype>
struct
compute_density_diffusion<BREZZI, boundarytype, cptype, PT_FLUID>
{
	template<typename FP, typename Pt, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, Pt const& pdata, N const& ndata, ON &nout)
	{
		// this is the new volumic term for the laplacian: dt Div(1/rho Grad(p) + Grad(g.r))
		nout.DrDt += d_densityDiffCoeff*((2.0f/(pdata.vel.w + ndata.relVel.w))*
					  (P(pdata.vel.w, fluid_num(pdata.info)) - P(ndata.relVel.w, fluid_num(ndata.info)))
					  - dot(d_gravity, as_float3(ndata.relPos))
					 )*ndata.relPos.w/ndata.relVel.w*ndata.f*params.dt*2.0f*pdata.vel.w;
	}
};

/// Diffusion term for Brezzi for boundary neighbours in the case of semi-analytical boundaries
template<ParticleType cptype>
struct
compute_density_diffusion<BREZZI, SA_BOUNDARY, cptype, PT_BOUNDARY>
{
	template<typename FP, typename Pt, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, Pt const& pdata, N const& ndata, ON &nout)
	{
		// for pressure inlets we need to compute a boundary term for the Rhie & Chow filter
		// the term is essentially the same as the one for the fluid particle except that V_b w' -> |ggam|/r_{as}
		if (IO_BOUNDARY(ndata.info) && PRES_IO(ndata.info))
			nout.DrDt -= ((2.0/(pdata.vel.w + ndata.relVel.w))*
						  (P(pdata.vel.w, fluid_num(pdata.info)) - P(ndata.relVel.w, fluid_num(ndata.info)))
						  - dot(d_gravity, as_float3(ndata.relPos))
						 )*nout.ggamAS/ndata.r_as*params.dt*2.0f*pdata.vel.w;
	}
};

/// Diffusion term for Colagrossi for fluid neighbours
/// following Molteni & Colagrossi 2009
template<BoundaryType boundarytype,
		ParticleType cptype>
struct
compute_density_diffusion<COLAGROSSI, boundarytype, cptype, PT_FLUID>
{
	template<typename FP, typename Pt, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, Pt const& pdata, N const& ndata, ON &nout)
	{
		const int fType = fluid_num(pdata.info);
		/* only applies to same-fluid particles */
		if (fType != fluid_num(ndata.info))
			return;

		// only apply diffusion for large density ratios, specifically
		// when DeltaP < rhogh
		if (fabs(P(pdata.vel.w, fType) - P(ndata.relVel.w, fType)) <
			fabs(dot3(d_gravity, ndata.relPos)*pdata.vel.w))
			return;

		// The contribution is \xi h c_0 \psi_ij \dot \grad W_ij dV_j where
		// \psi_ij = 2(vol_i/vol_j - 1) (x_i-x_j)/|x_i - x_j|.
		// given \grad W_ij = (x_i - x_j) F_ij, \psi_ij \grad W_i simplifies to
		// 2(vol_i/vol_j - 1) F_ij
		// For us rhodiffcoeff = \xi*h*2
		// Additionally, when the density evolution formulation is NOT based on
		// volumes, we need to multiply by the neighbor mass

		// TODO templetize on sph_formulation
		const bool has_volume = (FP::sph_formulation == SPH_GRENIER);
		const float diff_term = d_densityDiffCoeff*d_sscoeff[fType]*
			(volume_ratio<has_volume>::with(pdata, ndata) - 1)*
			ndata.f*(has_volume ? -1 : ndata.relPos.w);

		// TODO consider diff_term * W_ij/W(d/2) for dynamic problems

		nout.DrDt -= diff_term;
	}
};

struct generic_compute_density_derivative {
	// auxiliary function
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	common_with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// this should be divided by the neib density (ndata.relVel.w),
		// but would be multiplied by the same quantity in SPH_F1 formulation,
		// so we delegate the division to the caller, when needed
		// TODO this should be handled more intelligently, might require some
		// restructuring
		nout.DrDt = ndata.relPos.w*ndata.vel_dot_pos*ndata.f;
	}

	// update force.w
	template<typename OP, typename ON>
	__device__ __forceinline__
	static void
	update_drho_dt(OP &pout, ON const& nout)
	{ pout.force.w += nout.DrDt; }

	// update force.w
	template<typename FP, typename PD, typename N, typename ON>
	__device__ __forceinline__
	static void
	generic_compute_density_diffusion(FP const& params, PD const& pdata, N const& ndata, ON &nout)
	{
		compute_density_diffusion<FP::densitydiffusiontype, FP::boundarytype, FP::cptype, FP::nptype>::with(params, pdata, ndata, nout);
	}

	// actual method
	template<typename FP, typename PD, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, PD const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		if (FP::sph_formulation == SPH_GRENIER) {
			// for Grenier's formulation, DrDt is actually DJ/Dt, which needs to be divided
			// by the particle sigma, which will be done at the end of the cycle
			nout.DrDt -= ndata.vel_dot_pos*ndata.f;
			// TODO Ferrari correction
		} else {
			// SPH_F1 or SPH_F2
			common_with(params, pdata, ndata, pout, nout);
		}
		// Density diffusion
		generic_compute_density_diffusion(params, pdata, ndata, nout);
		/* The second formulation takes into consideration the density ratio */
		if (FP::sph_formulation == SPH_F2)
			nout.DrDt *= pdata.vel.w/ndata.relVel.w;

		/* Add contribution to density derivative */
		update_drho_dt(pout, nout);
	}
};

/// Generic version, no overrides
template<DensityDiffusionType densitydiffusiontype,
		BoundaryType boundarytype,
		ParticleType cptype,
		ParticleType nptype>
struct compute_density_derivative : public generic_compute_density_derivative
{};

// Specialization of compute_density_derivative for SA_BOUNDARY when neib is PT_FLUID or PT_VERTEX
template<DensityDiffusionType densitydiffusiontype,
		ParticleType nptype>
struct compute_density_derivative<densitydiffusiontype, SA_BOUNDARY, PT_FLUID, nptype> : generic_compute_density_derivative
{
	template<typename FP, typename PD, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, PD const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		common_with(params, pdata, ndata, pout, nout);

		// Density diffusion
		generic_compute_density_diffusion(params, pdata, ndata, nout);

		/* The second formulation takes into consideration the density ratio */
		if (FP::sph_formulation == SPH_F2)
			nout.DrDt *= pdata.vel.w/ndata.relVel.w;

		/* Add contribution to density derivative */
		update_drho_dt(pout, nout);
	}
};

// Specialization of compute_density_derivative for SA_BOUNDARY when neib is PT_BOUNDARY
template<DensityDiffusionType densitydiffusiontype>
struct compute_density_derivative<densitydiffusiontype, SA_BOUNDARY, PT_FLUID, PT_BOUNDARY> : generic_compute_density_derivative
{
	template<typename FP, typename PD, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, PD const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// Boundary term for div(v)
		nout.DrDt -= pdata.vel.w*dot3(ndata.relVel, ndata.belem)*nout.ggamAS;

		// Density diffusion
		generic_compute_density_diffusion(params, pdata, ndata, nout);

		/* Add contribution to density derivative */
		update_drho_dt(pout, nout);
	}
};

/// Functor to compute the pressure contribution to the particle acceleration.
/// The results should be stored in nout.DvDt
struct generic_compute_pressure_contrib
{
	// auxiliary function, which is used as fallback also in the SA_BOUNDARY case
	// responsible for the volumic term, note that p_precalc can contain 2/3 \rho k if KEPSVISC is chosen
	template<typename FP, typename P_t, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static float
	common_with(FP const& params, P_t const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		float pGradTerm = 0.0f;
		switch (FP::sph_formulation) {
		case SPH_F1:
			pGradTerm = pdata.p_precalc + ndata.p_precalc;
			break;
		case SPH_F2:
			pGradTerm = (pdata.p_precalc + ndata.p_precalc)/(pdata.vel.w*ndata.relVel.w);
			break;
		case SPH_GRENIER:
			pGradTerm = pdata.p_precalc + ndata.p_precalc;
			// simplified surface tension correction, applied if neighbor is FLUID
			// of different type
			// (TODO optimization: the FLUID check is needed in DYN_BOUNDARY case only)
			if (FLUID(ndata.info) && fluid_num(pdata.info) != fluid_num(ndata.info))
				pGradTerm += d_epsinterface*(fabs(pdata.p_precalc) + fabs(ndata.p_precalc));
			break;
		}
		return pGradTerm;
	}

	// actual method to compute the full pressure gradient in the non SA_BOUNDARY case
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		const float pGradTerm(common_with(params, pdata, ndata, pout, nout));
		if (FP::sph_formulation == SPH_GRENIER) {
			nout.DvDt -= pGradTerm*ndata.f*as_float3(ndata.relPos);
		} else {
			nout.DvDt -= pGradTerm*ndata.relPos.w*ndata.f*as_float3(ndata.relPos);
		}
	}
};

/// Generic version, no overrides
template<BoundaryType boundarytype,
		ParticleType cptype,
		ParticleType nptype>
struct compute_pressure_contrib : public generic_compute_pressure_contrib
{};

template<>
struct compute_pressure_contrib<SA_BOUNDARY, PT_FLUID, PT_BOUNDARY> :
public generic_compute_pressure_contrib
{
	// actual method: will need specializations depending on the particle types, so here it is just declared
	template<typename FP, typename PD, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, PD const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// general pressure term
		const float pGradTerm(common_with(params, pdata, ndata, pout, nout));
		nout.DvDt += pGradTerm*ndata.relVel.w*nout.ggamAS*ndata.normal_s;
	}
};

/// A functor that computes the mean velocity (XSPH)
template<bool usexsph>
struct compute_mean_vel
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_mean_vel<true>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	pout.mean_vel -= ndata.relPos.w*W<FP::kerneltype>(ndata.r, params.slength)*as_float3(ndata.relVel)/(pdata.vel.w + ndata.relVel.w);
}


/// A function that computes simple fluid/boundary forces (LJ, MK)
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__
void compute_repulsive_force(FP const& params, P const& pdata, N const& ndata,
	OP &pout, ON &nout)
{
	switch (FP::boundarytype) {
	case LJ_BOUNDARY:
		nout.DvDt = LJForce(ndata.r)*as_float3(ndata.relPos);
		break;
	case MK_BOUNDARY:
		nout.DvDt = MKForce(ndata.r, params.slength, pdata.pos.w, pdata.pos.w)*as_float3(ndata.relPos);
		break;
	default:
		/* do nothing */
		break;
	}
}

// Function that returns the relative velocity to be used in viscous computation.
// This is just relVel normally, but it's relVel + relEulerVel when the neighbor
// has an associated eulerian velocity.

template<typename N>
using has_eulerVel = std::is_base_of<eulerVel_neib_data, N>;

template<typename N, typename T>
using enable_if_eulerVel = typename std::enable_if<has_eulerVel<N>::value, T>::type;
template<typename N, typename T>
using enable_if_not_eulerVel = typename std::enable_if<!has_eulerVel<N>::value, T>::type;

template<typename N>
__device__ __forceinline__
enable_if_not_eulerVel<N, float4> get_viscous_relVel(N const& ndata)
{ return ndata.relVel; } /* Standard case */

template<typename N>
__device__ __forceinline__
enable_if_eulerVel<N, float4> get_viscous_relVel(N const& ndata)
{ return ndata.relVel + ndata.relEulerVel; } /* eulerVel case */

// auxiliary functor computing boundary contribution to the viscous term
// note that these boundary contributions are specialized for SA_BOUNDARY.
// As no other boundary condition has any boundary terms there is no need to add another template parameter
template<ViscosityType visctype>
struct visc_boundary_part {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{}
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_boundary_part<DYNAMICVISC>::with
(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// velocity of fluid particle along the wall
	const float3 vel_tau = as_float3(get_viscous_relVel(ndata)) -
		(IO_BOUNDARY(ndata.info) ?
		 make_float3(0.0f) :
		 dot(as_float3(get_viscous_relVel(ndata)), ndata.normal_s)*ndata.normal_s
		);


	nout.DvDt -= nout.ggamAS*
		(d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w + d_visccoeff[fluid_num(ndata.info)]*ndata.relVel.w)/ndata.r_as*
		vel_tau/pdata.vel.w;
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_boundary_part<KEPSVISC>::with
(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (IO_BOUNDARY(ndata.info)) {
		// velocity of fluid particle along the wall
		const float3 vel_tau = as_float3(ndata.relVel + ndata.relEulerVel);

		nout.DvDt -= nout.ggamAS*
			(d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w + d_visccoeff[fluid_num(ndata.info)]*ndata.relVel.w)/ndata.r_as*
			vel_tau/pdata.vel.w;
		return;
	}

	// for boundary particles without neighbouring fluid particle k is 0 so skip
	if(pdata.keps_k < params.epsilon)
		return;
	// a component of fluid paricle velocity tangential to the wall
	const float3 u_t = as_float3(ndata.relVel+pdata.eulerVel) - dot(as_float3(ndata.relVel+pdata.eulerVel), ndata.normal_s)*ndata.normal_s;
	const float abs_u_t = length(u_t);

	// we solve iteratively the wall law equation to obtain y+ value
	float u_star = 0.0f;
	// the constant is equal to 0.09^0.25
	const float uk = 0.547722558f*sqrt(pdata.keps_k);
	float y_plus = ndata.r_as/d_visccoeff[fluid_num(pdata.info)]*uk;
	// constant is equal to 1/0.41
	if(y_plus < 2.43902439f) // viscous sublayer
		u_star = abs_u_t/y_plus;
	else{ // log law
		// constant is equal to exp(-5.2*0.41)
		float utau = 0.118599857f*d_visccoeff[fluid_num(ndata.info)]/ndata.r_as;
		for (int i=0; i<10; i++) {
			// constant is equal to 1/0.41
			y_plus = fmax(ndata.r_as*utau/d_visccoeff[fluid_num(ndata.info)], 2.43902439f);
			// constant is equal to 5.2*0.41+1
			utau = (0.41f*abs_u_t + utau)/(log(y_plus) + 3.132f);
		}
		u_star = abs_u_t / (log(y_plus)/0.41f + 5.2f);
	}

	nout.DvDt -= 2.0f*nout.ggamAS*u_star*u_star*u_t/fmax(abs_u_t,1e-6f);
}

// auxiliary functor computing volumic contribution to the viscous term
template<ViscosityType visctype>
struct visc_volumic_part {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout);
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<DYNAMICVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	const float visc(laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f,
				d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w, d_visccoeff[fluid_num(ndata.info)]*ndata.relVel.w));
	nout.DvDt += visc*as_float3(get_viscous_relVel(ndata));
}

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<KINEMATICVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	const float visc(laminarvisc_kinematic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f));
	nout.DvDt += visc*as_float3(get_viscous_relVel(ndata));
}

// SPS viscosity is just kinematic + a contribution based on the strain rate
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<SPSVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	nout.DvDt.x += ndata.relPos.w*ndata.f*(
		(pdata.tau.xx + ndata.tau.xx)*ndata.relPos.x +
		(pdata.tau.xy + ndata.tau.xy)*ndata.relPos.y +
		(pdata.tau.xz + ndata.tau.xz)*ndata.relPos.z);
	nout.DvDt.y += ndata.relPos.w*ndata.f*(
		(pdata.tau.xy + ndata.tau.xy)*ndata.relPos.x +
		(pdata.tau.yy + ndata.tau.yy)*ndata.relPos.y +
		(pdata.tau.yz + ndata.tau.yz)*ndata.relPos.z);
	nout.DvDt.z += ndata.relPos.w*ndata.f*(
		(pdata.tau.xz + ndata.tau.xz)*ndata.relPos.x +
		(pdata.tau.yz + ndata.tau.yz)*ndata.relPos.y +
		(pdata.tau.zz + ndata.tau.zz)*ndata.relPos.z);
	const float visc(laminarvisc_kinematic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f));
	nout.DvDt += visc*as_float3(ndata.relVel);
}

// k-e viscosity: dynamic + turbulent
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<KEPSVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	const float visc(laminarvisc_dynamic(pdata.vel.w, ndata.relVel.w, ndata.relPos.w, ndata.f,
		(d_visccoeff[fluid_num(pdata.info)]+pdata.turbViscForViscTerm)*pdata.vel.w,
		(d_visccoeff[fluid_num(ndata.info)]+ndata.turbViscForViscTerm)*ndata.relVel.w));
	// call getRelEulerVel always with true as in keps we always have that value
	nout.DvDt += visc*as_float3(get_viscous_relVel(ndata));
}

// artificial viscosity
template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
visc_volumic_part<ARTVISC>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	if (ndata.vel_dot_pos < 0.0f){
		const float visc = artvisc(ndata.vel_dot_pos, pdata.vel.w, ndata.relVel.w,
			pdata.sspeed, ndata.sspeed, ndata.r, params.slength);
		// note that here we use the position difference and not the velocity difference
		nout.DvDt += visc*as_float3(ndata.relPos)*ndata.relPos.w*ndata.f;
	}
}

/// A functor that computes the scalar viscous coefficient (plus additional optional contributions
/// directly to nout.
/// See above about the double template<> in the specializations
struct generic_compute_viscous_contrib {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout){
		// in the generic case only the volumic term is of interest
		visc_volumic_part<FP::visctype>::with(params, pdata, ndata, pout, nout);
	}

};

template<BoundaryType boundarytype,
		SPHFormulation sph_formulation,
		ParticleType cptype,
		ParticleType nptype>
struct compute_viscous_contrib : public generic_compute_viscous_contrib
{};


/// Specialization for SA_BOUNDARY
template<SPHFormulation sph_formulation,
		ParticleType cptype,
		ParticleType nptype>
struct compute_viscous_contrib<SA_BOUNDARY, sph_formulation, cptype, nptype> : public generic_compute_viscous_contrib {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// volumic term of the viscous part using vertices and fluid particles (same as in the generic case)
		visc_volumic_part<FP::visctype>::with(params, pdata, ndata, pout, nout);
	}
};

template<SPHFormulation sph_formulation,
		ParticleType cptype>
struct compute_viscous_contrib<SA_BOUNDARY, sph_formulation, cptype, PT_BOUNDARY> : public generic_compute_viscous_contrib {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		visc_boundary_part<FP::visctype>::with(params, pdata, ndata, pout, nout);
	}
};

/// Specialization for SPH_GRENIER
template<BoundaryType boundarytype,
		ParticleType cptype,
		ParticleType nptype>
struct compute_viscous_contrib<boundarytype, SPH_GRENIER, cptype, nptype> : public generic_compute_viscous_contrib {
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// TODO support different visctypes, currently we just ignore it
		const float mu_i = d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w;
		const float mu_j = d_visccoeff[fluid_num(ndata.info)]*ndata.relVel.w;
		const float avg_mu = 2*(mu_i*mu_j)/(mu_i+mu_j);
		const float avg_sigma = (1/pdata.sigma + 1/ndata.sigma);
		nout.DvDt += avg_mu*avg_sigma*ndata.f*as_float3(ndata.relVel);
	}
};

/// Functor to compute the KEPS diffusion and velocity gradient terms
struct generic_compute_keps_term
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<BoundaryType boundarytype,
		ViscosityType visctype,
		ParticleType cptype,
		ParticleType nptype>
struct compute_keps_term : public generic_compute_keps_term
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

//k-e computation for SA and PT_FLUID <= PT_FLUID or PT_VERTEX
template<ParticleType cptype,
		ParticleType nptype>
struct compute_keps_term<SA_BOUNDARY, KEPSVISC, cptype, nptype> : public generic_compute_keps_term
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// volume contribution for k and epsilon diffusion terms
		pout.diff_term_k += ndata.relPos.w*(
			pdata.dkdt_precalc + ndata.relVel.w*(d_visccoeff[fluid_num(ndata.info)] + ndata.turbVisc)
			)*(pdata.keps_k - ndata.keps_k)*ndata.f/ndata.relVel.w;
		pout.diff_term_e += ndata.relPos.w*(
			pdata.dedt_precalc + ndata.relVel.w*(d_visccoeff[fluid_num(ndata.info)] + ndata.turbVisc/1.3f)
			)*(pdata.keps_e - ndata.keps_e)*ndata.f/ndata.relVel.w;

		// multiplication for velocity gradient terms (- m_b*r_ab*gradW)
		const float3 dvmul = -ndata.relPos.w*as_float3(ndata.relPos)*ndata.f ;

		// velocity gradient
		// From fluid/vertex:
		//	dvx = -∑mb vxab ∇(ra - rb)/r ∂Wab/∂r
		//	dvy = -∑mb vyab ∇(ra - rb)/r ∂Wab/∂r
		//	dvz = -∑mb vzab ∇(ra - rb)/r ∂Wab/∂r

		const float4 visc_relVel = get_viscous_relVel(ndata);
		pout.dvx += visc_relVel.x*dvmul;
		pout.dvy += visc_relVel.y*dvmul;
		pout.dvz += visc_relVel.z*dvmul;
	}
};

//k-e computation for SA and PT_FLUID <= PT_BOUNDARY
template<ParticleType cptype>
struct compute_keps_term<SA_BOUNDARY, KEPSVISC, cptype, PT_BOUNDARY> : public generic_compute_keps_term
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{
		// Yap correction
		// constant is 0.09^0.75/0.41
		const float lyap = 0.400772603f*powf(pdata.keps_k,1.5f)/(pdata.keps_e*ndata.r_as);
		if (lyap > 1.0f)
			pout.ce2yap = fmin(pout.ce2yap, fmax(1.92f - 0.83f*(lyap-1.0f)*lyap*lyap, 0.0f));

		// boundary contribution to epsilon diffusion term
		// the constant factor is 4.0f*0.09/1.3 where 0.09 = C_\mu and 1.3 = \sigma_\epsilon
		pout.diff_term_e += 0.276923077f*pdata.keps_k*pdata.keps_k/ndata.r_as*nout.ggamAS;

		// multiplication for velocity gradient terms (gradGam_as*rho_s)
		const float3 dvmul = nout.ggamAS*ndata.normal_s*ndata.relVel.w;

		// velocity gradient
		// From boundary:
		//	dvx = ∑ρs vxas ∇γas
		//	dvy = ∑ρs vyas ∇γas
		//	dvz = ∑ρs vzas ∇γas

		pout.dvx += (ndata.relVel.x+ndata.relEulerVel.x)*dvmul;
		pout.dvy += (ndata.relVel.y+ndata.relEulerVel.y)*dvmul;
		pout.dvz += (ndata.relVel.z+ndata.relEulerVel.z)*dvmul;
	}
};

/*
 * Post-processing and saving
 */


/// The next set of functors post-process the particle forces and write them to
/// the appropriate given arrays


/// A functor that does viscosity-related post-processing, and returns a
/// viscous coefficient to be used with DEMs and planes
template<ViscosityType>
struct viscous_fixup
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static float
	with(FP const& params, P const& pdata, OP &pout);
};

/// Specializations

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<DYNAMICVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w; }

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<KINEMATICVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w/4; } // TODO FIXME check?

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<SPSVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w/4; } // TODO FIXME check?

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<ARTVISC>::with(FP const& params, P const& pdata, OP &pout)
{ return 0; } // assumes free-slip

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ float
viscous_fixup<KEPSVISC>::with(FP const& params, P const& pdata, OP &pout)
{
	// final division for diff and dv{x,y,z} terms
	const float rhoGam = pdata.vel.w*pout.gGam.w;
	// finalize diffusion terms
	pout.diff_term_k /= rhoGam;
	pout.diff_term_e /= rhoGam;
	// finalize velocity gradients
	pout.dvx /= rhoGam;	// dvx = -1/γa*ρa ∑mb vxab (ra - rb)/r ∂Wab/∂r
	pout.dvy /= rhoGam;	// dvy = -1/γa*ρa ∑mb vyab (ra - rb)/r ∂Wab/∂r
	pout.dvz /= rhoGam;	// dvz = -1/γa*ρa ∑mb vzab (ra - rb)/r ∂Wab/∂r
	// Calculate norm of the mean strain rate tensor
	float SijSij_bytwo = 2.0f*(pout.dvx.x*pout.dvx.x +
		pout.dvy.y*pout.dvy.y +
		pout.dvz.z*pout.dvz.z);	// 2*SijSij = 2.0((∂vx/∂x)^2 + (∂vy/∂yx)^2 + (∂vz/∂z)^2)
	float temp = pout.dvx.y + pout.dvy.x;
	SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vx/∂y + ∂vy/∂x)^2
	temp = pout.dvx.z + pout.dvz.x;
	SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vx/∂z + ∂vz/∂x)^2
	temp = pout.dvy.z + pout.dvz.y;
	SijSij_bytwo += temp*temp;		// 2*SijSij += (∂vy/∂z + ∂vz/∂y)^2
	// Strain rate
	const float S = sqrtf(SijSij_bytwo);
	// production of turbulent kinetic energy (TKE)
	const float Pturb = fmin(pdata.turbVisc*SijSij_bytwo, 0.3f*pdata.keps_k*S);
	//const float Pturb = fmin(0.3f, 0.09f*pdata.keps_k/pdata.keps_e*S)*pdata.keps_k*S;

	// Variation terms for Dk/Dt and De/Dt for the partially implicit time integration in euler
	const float dkdt = Pturb + pout.diff_term_k;
	const float dedt = pdata.keps_e*1.44f*Pturb/pdata.keps_k + pout.diff_term_e;

	params.keps_dkde[pdata.index].x = dkdt;
	params.keps_dkde[pdata.index].y = dedt;
	params.keps_dkde[pdata.index].z = pout.ce2yap;

	return d_visccoeff[fluid_num(pdata.info)]*pdata.vel.w;
}

/// A functor to do global corrections of particle forces, such as multiplication
/// or division by a common factor
template<SPHFormulation sph_formulation>
struct forces_fixup
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP &pout)
	{ /* do nothing */ }
};

/// In Grenier, we compute DJ/Dt without the 1/sigma factor in front,
/// and DvDt without the 1/\rho factor in front. Do the division in forces_fixup
template<>
struct forces_fixup<SPH_GRENIER>
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP &pout)
	{
		pout.force.x /= pdata.vel.w;
		pout.force.y /= pdata.vel.w;
		pout.force.z /= pdata.vel.w;
		pout.force.w /= pdata.sigma;
	}
};




/// A functor that clamps gamma and divides force by it,
/// but only for SA_BOUNDARY
template<BoundaryType>
struct gamma_fixup
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP &pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
gamma_fixup<SA_BOUNDARY>::with(FP const& params, P const& pdata, OP &pout)
{
	// in case of density sum we compute gamma in euler so it's
	// already available here
	// TODO avoid computation before
	//if(FP::simflags & ENABLE_DENSITY_SUM && pdata.oldGGam.w > 1e-5f)
	//	pout.gGam = pdata.oldGGam;
	pout.force.x /= pdata.gGam.w;
	pout.force.y /= pdata.gGam.w;
	pout.force.z /= pdata.gGam.w;
	pout.force.w /= pdata.gGam.w;
	if (FP::sph_formulation == SPH_F2 && !(FP::simflags & ENABLE_DENSITY_SUM))
		pout.force.w *= pdata.vel.w;
}

/// A functor that computes the force acting on a boundary element
/// but only for SA_BOUNDARY
template<BoundaryType>
struct compute_boundary_force
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP &pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename PD, typename OP>
__device__ __forceinline__ void
compute_boundary_force<SA_BOUNDARY>::with(FP const& params, PD const& pdata, OP &pout)
{
	// Force = -Pressure*SurfaceArea*NormalOutsideVector
	pout.force = -P(pdata.vel.w, fluid_num(pdata.info))*pdata.belem.w*pdata.belem;
	pout.force.w = 0.0f;
}

/// A functor that computes the water depth at an outflow
template<BoundaryType, bool use_water_depth>
struct compute_water_depth_at_outflow
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename N, typename OP, typename ON>
__device__ __forceinline__ void
compute_water_depth_at_outflow<SA_BOUNDARY, true>::with(FP const& params, P const& pdata, N const& ndata, OP &pout, ON &nout)
{
	// note all computations here are done assuming that the gravity vector points in z direction only
	// if the fluid particle is higher than the vertex particle then don't continue (saves a few atomics)
	if (ndata.ntype != PT_FLUID || ndata.relPos.z < 0.0f)
		return;
	// z position of fluid particle with respect to world_origin
	float nZpos = pdata.pos.z - ndata.relPos.z + pdata.gridPos.z*d_cellSize.z + 0.5f*d_cellSize.z;
	// position between 0 and UINT_MAX:
	nZpos *= ((float) UINT_MAX)/(d_gridSize.z*d_cellSize.z);
	atomicMax(&params.IOwaterdepth[object(pdata.info)], (uint)nZpos);
}

/// A functor that adds the internal energy contribution from a neighbor
/// to the total one, if ENABLE_INTERNAL_ENERGY
template<bool>
struct add_internal_energy
{
	template<typename OP, typename N, typename ON>
	__device__ __forceinline__
	static void
	with(OP &pout, N const& ndata, ON const& nout)
	{ /* do nothing */ }
};

template<>
template<typename OP, typename N, typename ON>
__device__ __forceinline__ void
add_internal_energy<true>::with(OP &pout, N const& ndata, ON const& nout)
{
	pout.DEDt -= dot3(nout.DvDt, ndata.relVel)/2;
}


/// A functor that writes out gamma,
/// but only for SA_BOUNDARY
template<BoundaryType boundarytype,
		ParticleType cptype,
		bool dynamic_gamma>
struct write_gamma
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP& pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_gamma<SA_BOUNDARY, PT_BOUNDARY, false>::with(FP const& params, P const& pdata, OP& pout)
{
	params.newGGam[pdata.index] = pout.gGam;
	//if ((FP::simflags & ENABLE_INLET_OUTLET && !pdata.computeGamma && IO_BOUNDARY(pdata.info) && !VEL_IO(pdata.info)) ||
	//	(FP::simflags & ENABLE_DENSITY_SUM && pdata.oldGGam.w > 1e-5f && (params.step==1 || pdata.ptype != PT_FLUID)))
	//	params.newGGam[pdata.index] = pdata.oldGGam;
	//else if (!((FP::simflags & ENABLE_DENSITY_SUM) && params.step==2)) {
	//	// Gamma clipping (was previously in gamma_fixup)
	//	pout.gGam.w = fmin(fmax(pout.gGam.w, params.epsilon), 1.0f);
	//	params.newGGam[pdata.index] = pout.gGam;
	//}
}

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_gamma<SA_BOUNDARY, PT_BOUNDARY, true>::with(FP const& params, P const& pdata, OP& pout)
{
	// only update gradient of gamma
	as_float3(params.newGGam[pdata.index]) = as_float3(pout.gGam);
	//if ((FP::simflags & ENABLE_INLET_OUTLET && !pdata.computeGamma && IO_BOUNDARY(pdata.info) && !VEL_IO(pdata.info)) ||
	//	(FP::simflags & ENABLE_DENSITY_SUM && pdata.oldGGam.w > 1e-5f && (params.step==1 || pdata.ptype != PT_FLUID)))
	//	params.newGGam[pdata.index] = pdata.oldGGam;
	//else if (!((FP::simflags & ENABLE_DENSITY_SUM) && params.step==2)) {
	//	// Gamma clipping (was previously in gamma_fixup)
	//	pout.gGam.w = fmin(fmax(pout.gGam.w, params.epsilon), 1.0f);
	//	params.newGGam[pdata.index] = pout.gGam;
	//}
}

/// A funcion that writes out gammaCfl, if present
template<typename FP, typename P, typename OP>
__device__ __forceinline__
enable_if_gammaCfl<OP>
write_gamma_cfl(FP const& params, P const& pdata, OP& pout)
{
	params.cfl_gamma[pdata.index] = pout.gammaCfl;
}

/// write_gamma_cfl is there is no gammaCfl
template<typename FP, typename P, typename OP>
__device__ __forceinline__
enable_if_not_gammaCfl<OP>
write_gamma_cfl(FP const& params, P const& pdata, OP& pout)
{ /* do nothing */ }


/// A functor that writes out the mean vel,
/// but only for XSPH
template<bool>
struct write_xsph
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_xsph<true>::with(FP const& params, P const& pdata, OP const& pout)
{ params.xsph[pdata.index] = make_float4(2.0f*pout.mean_vel, 0.0f); }

/// A functor that writes out the internal energy, if enabled
template<bool>
struct write_internal_energy
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_internal_energy<true>::with(FP const& params, P const& pdata, OP const& pout)
{ params.DEDt[pdata.index] = pout.DEDt; }


/// A functor that writes out turbvisc
/// but only for KEPSVISC
template<ViscosityType>
struct write_turbvisc
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__ void
write_turbvisc<KEPSVISC>::with(FP const& params, P const& pdata, OP const& pout)
{ params.turbvisc[pdata.index] = pdata.turbVisc; }


/// A functor that writes out forces
template<BoundaryType boundarytype>
struct write_forces
{
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, OP const& pout)
	{
		params.forces[pdata.index] = pout.force;
	}
};

template<>
template<typename FP, typename P, typename OP>
__device__ __forceinline__
void
write_forces<SA_BOUNDARY>::with(FP const& params, P const& pdata, OP const& pout)
{
	params.forces[pdata.index].x = pout.force.x;
	params.forces[pdata.index].y = pout.force.y;
	params.forces[pdata.index].z = pout.force.z;
	params.forces[pdata.index].w = pout.force.w;
	params.dgamdt[pdata.index] = pout.dgamdt;
}

/*
 * Global variables
 */

/// Some forces kernel specializations have global variables which are not individual particle data
/// and are therefore collected here. Since we can have a wide combination of these
/// blocks, we define a common infrastructure for them, and we call the method
/// for each of the parent structures. Therefore, the alternative in case of a missing
/// structure cannot be the empty struct, as it must provide the needed interface

template<typename T>
struct dyndt_shared_none
{
	// init shared data
	__device__ __forceinline__ void
	init() { /* do nothing */ }

	// store shared data
	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{ /* do nothing */ }

	// reduce shared data
	template<typename FP>
	__device__ __forceinline__ void
	reduce(FP const& params)
	{ /* do nothing */ }
};

#define COND_SHARED(some_cond, some_struct) \
	conditional<some_cond, some_struct, dyndt_shared_none<some_struct> >::type

struct dyndt_forces_shared_data
{
	float sm_forces_max[BLOCK_SIZE_FORCES];

	__device__ __forceinline__ void
	init() { sm_forces_max[threadIdx.x] = 0; }

	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{
		sm_forces_max[threadIdx.x] = length(as_float3(pout.force));
	}

	template<typename FP>
	__device__ __forceinline__ void
	reduce(FP const& params)
	{
		dtadaptBlockReduce(this->sm_forces_max, params.cfl_forces, params.cflOffset);
	}
};

struct dyndt_gamma_shared_data
{
	float sm_gamma_max[BLOCK_SIZE_FORCES];

	__device__ __forceinline__ void
	init() { sm_gamma_max[threadIdx.x] = 0; }

	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{
		sm_gamma_max[threadIdx.x] = pout.gammaCfl;
	}

	template<typename FP>
	__device__ __forceinline__ void
	reduce(FP const& params)
	{
		dtadaptBlockReduce(sm_gamma_max, params.cfl_gamma, params.cflOffset);
	}
};

struct dyndt_keps_shared_data
{
	float sm_keps_max[BLOCK_SIZE_FORCES];

	__device__ __forceinline__ void
	init() { sm_keps_max[threadIdx.x] = 0; }

	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{
		sm_keps_max[threadIdx.x] = pdata.turbVisc;
	}

	template<typename FP>
	__device__ __forceinline__ void
	reduce(FP const& params)
	{
		dtadaptBlockReduce(sm_keps_max, params.cfl_keps, params.cflOffset);
	}
};

template<BoundaryType boundarytype, ViscosityType visctype, flag_t simflags,
	bool dtadapt = simflags & ENABLE_DTADAPT>
struct forces_shared_data :
	COND_SHARED(dtadapt, dyndt_forces_shared_data),
	COND_SHARED(dtadapt && USING_DYNAMIC_GAMMA(simflags) && boundarytype == SA_BOUNDARY,
		dyndt_gamma_shared_data),
	COND_SHARED(dtadapt && visctype == KEPSVISC,
		dyndt_keps_shared_data)
{
	typedef
		typename COND_SHARED(dtadapt, dyndt_forces_shared_data)
		common;
	typedef
		typename COND_SHARED(dtadapt && USING_DYNAMIC_GAMMA(simflags) &&
			boundarytype == SA_BOUNDARY, dyndt_gamma_shared_data)
		gamma;
	typedef
		typename COND_SHARED(dtadapt && visctype == KEPSVISC,
			dyndt_keps_shared_data)
		keps;

	__device__ __forceinline__ void
	init()
	{
		common::init();
		gamma::init();
		keps::init();
	}

	template<typename FP, typename P, typename OP>
	__device__ __forceinline__ void
	store(FP const& params, P const& pdata, OP const& pout)
	{
		common::store(params, pdata, pout);
		gamma::store(params, pdata, pout);
		keps::store(params, pdata, pout);
	}

	template<typename FP>
	__device__ __forceinline__ void
	reduce(FP const& params)
	{
		common::reduce(params);
		gamma::reduce(params);
		keps::reduce(params);
	}
};


/************************************************************************************************************/
/*		   Particle-particle interaction											                        */
/************************************************************************************************************/
/// A functor that computes particle-particle interaction
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags,
	ParticleType cptype,
	ParticleType nptype>
struct compute_pp_interaction
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{ /* do nothing */ }
};

/// Specialization of particle-particle interaction for the fluid-fluid case
/* When both the central particle and their neighbors are fluid the interaction
 * is the same regardless of the boundary type and is computed in this specialized
 * functor.
 */
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, PT_FLUID, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		if (!(simflags & ENABLE_DENSITY_SUM)) { // AM-TODO: this if can be probably removed
			// Computes d\rho/dt, including density diffusion
			compute_density_derivative<densitydiffusiontype, boundarytype, PT_FLUID, PT_FLUID>::with(params, pdata, ndata, pout, nout);
		}

		// Compute pressure part of acceleration
		compute_pressure_contrib<boundarytype, PT_FLUID, PT_FLUID>::with(params, pdata, ndata, pout, nout);

		// Compute viscous forces
		compute_viscous_contrib<boundarytype, sph_formulation, PT_FLUID, PT_FLUID>::with(params, pdata, ndata, pout, nout);

		// Compute diffusion terms for k-epsilon and the strain rate tensor
		compute_keps_term<boundarytype, visctype, PT_FLUID, PT_FLUID>::with(params, pdata, ndata, pout, nout);

		// Compute mean velocity for the use in the XSPH variant. Contribution added in euler.
		compute_mean_vel<simflags & ENABLE_XSPH>::with(params, pdata, ndata, pout, nout);

		// Sum all contributions from the neighbors in the force array
		as_float3(pout.force) += nout.DvDt;
		// Summ all internal energy contributions from the neighbors
		add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
	}
};


/// Generic specialization of particle-particle interaction for boundary-fluid
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, PT_BOUNDARY, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{ /* do nothing */ }
};


template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, LJ_BOUNDARY, visctype, simflags, PT_BOUNDARY, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		// We need to compute force on boundary particles only when we have floating bodies or force feedback
		if (COMPUTE_FORCE(pdata.info)) {
			// Compute repulsive force from boundary particle
			compute_repulsive_force(params, pdata, ndata, pout, nout);

			// Sum all contributions from the neighbors in the force array
			as_float3(pout.force) += nout.DvDt;
			// Summ all internal energy contributions from the neighbors
			add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
		}
	}
};

template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, MK_BOUNDARY, visctype, simflags, PT_BOUNDARY, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		// We need to compute force on boundary particles only when we have floating bodies or force feedback
		if (COMPUTE_FORCE(pdata.info)) {
			// Compute repulsive force from boundary particle
			compute_repulsive_force(params, pdata, ndata, pout, nout);

			// Sum all contributions from the neighbors in the force array
			as_float3(pout.force) += nout.DvDt;
			// Summ all internal energy contributions from the neighbors
			add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
		}
	}
};

/// Generic specialization of particle-particle interaction for fluid-boundary
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, PT_FLUID, PT_BOUNDARY>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		if (boundarytype != LJ_BOUNDARY && boundarytype != MK_BOUNDARY)
			return;

		// Compute repulsive force from boundary particle
		compute_repulsive_force(params, pdata, ndata, pout, nout);

		// Sum all contributions from the neighbors in the force array
		as_float3(pout.force) += nout.DvDt;
		// Summ all internal energy contributions from the neighbors
		add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
	}
};


/// Specialization of particle-particle interaction for boundary-fluid with dynamic boundaries
/* When using dynamic boundaries the boundary-fluid interaction consist in the density derivative
 * computation for boundary particles and a full force computation if we need to compute the
 * force on a boundary.
 */
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, DYN_BOUNDARY, visctype, simflags, PT_BOUNDARY, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		if (!(simflags & ENABLE_DENSITY_SUM)) {
			// Computes d\rho/dt, including ferrari correction
			compute_density_derivative<densitydiffusiontype, DYN_BOUNDARY, PT_BOUNDARY, PT_FLUID>::with(params, pdata, ndata, pout, nout);
		}

		// We need to compute force on boundary particles only when we have floating bodies or force feedback
		if (COMPUTE_FORCE(pdata.info)) {
			// Compute pressure part of acceleration
			compute_pressure_contrib<DYN_BOUNDARY, PT_BOUNDARY, PT_FLUID>::with(params, pdata, ndata, pout, nout);

			// Compute viscous forces
			compute_viscous_contrib<DYN_BOUNDARY, sph_formulation, PT_BOUNDARY, PT_FLUID>::with(params, pdata, ndata, pout, nout);

			// Compute diffusion terms for k-epsilon and the strain rate tensor
			compute_keps_term<DYN_BOUNDARY, visctype, PT_BOUNDARY, PT_FLUID>::with(params, pdata, ndata, pout, nout);
			// TODO : implement keps for dynamic boundaries

			// Sum all contributions from the neighbors in the force array
			as_float3(pout.force) += nout.DvDt;
			// Summ all internal energy contributions from the neighbors
			add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
		}
	}
};


/// Specialization of particle-particle interaction for fluid-boundary with dynamic boundaries
/* When using dynamic boundaries the fluid-boundary interaction is the same as the fluid-fluid
 * except for the mean velocity with XSPH.
 * TODO: check if we need to compute the mean vel for XSPH including the boundary particles
 */
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, DYN_BOUNDARY, visctype, simflags, PT_FLUID, PT_BOUNDARY>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		if (!(simflags & ENABLE_DENSITY_SUM)) {
			// Computes d\rho/dt, including ferrari correction
			compute_density_derivative<densitydiffusiontype, DYN_BOUNDARY, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);
		}

		// Compute pressure part of acceleration
		compute_pressure_contrib<DYN_BOUNDARY, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);

		// Compute viscous forces
		compute_viscous_contrib<DYN_BOUNDARY, sph_formulation, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);

		// Compute diffusion terms for k-epsilon and the strain rate tensor
		compute_keps_term<DYN_BOUNDARY, visctype, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);
		// TODO : implement keps for dynamic boundaries

		// Sum all contributions from the neighbors in the force array
		as_float3(pout.force) += nout.DvDt;
		// Summ all internal energy contributions from the neighbors
		add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
	}
};


/// Specialization of particle-particle interaction for fluid-boundary with SA boundaries
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, SA_BOUNDARY, visctype, simflags, PT_FLUID, PT_BOUNDARY>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		// Compute gamma_as and |grad gamma_as| and add it to the respective values
		// of the focal particle
		compute_gamma<SA_BOUNDARY, PT_FLUID, USING_DYNAMIC_GAMMA(simflags)>::with(params, pdata, ndata, pout, nout);

		if (!(simflags & ENABLE_DENSITY_SUM)) {
			// Computes d\rho/dt, including ferrari correction
			compute_density_derivative<densitydiffusiontype, SA_BOUNDARY, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);
		}

		// Compute pressure part of acceleration
		compute_pressure_contrib<SA_BOUNDARY, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);

		// Compute viscous forces
		compute_viscous_contrib<SA_BOUNDARY, sph_formulation, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);

		// Compute diffusion terms for k-epsilon and the strain rate tensor
		compute_keps_term<SA_BOUNDARY, visctype, PT_FLUID, PT_BOUNDARY>::with(params, pdata, ndata, pout, nout);

		// Compute time derivative of gamma
		compute_gamma_dot<USING_DYNAMIC_GAMMA(simflags)>::with(params, pdata, ndata, pout, nout);

		// Sum all contributions from the neighbors in the force array
		as_float3(pout.force) += nout.DvDt;
		// Summ all internal energy contributions from the neighbors
		add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
	}
};

/// Specialization of particle-particle interaction for vertex-fluid with SA boundaries
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, SA_BOUNDARY, visctype, simflags, PT_VERTEX, PT_FLUID>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		// TODO: viscous contrib PT_VERTEX <= PT_FLUID

		// TODO: check what we need to do in that case
		// We need to compute force on boundary particles only when we have floating bodies or force feedback
		/*if (COMPUTE_FORCE(pdata.info)) {
			// Compute pressure part of acceleration
			compute_pressure_contrib<DYN_BOUNDARY>::with(params, pdata, ndata, pout, nout);

			// Compute viscous forces
			compute_viscous_contrib<DYN_BOUNDARY, sph_formulation>::with(params, pdata, ndata, pout, nout);

			// Sum all contributions from the neighbors in the force array
			as_float3(pout.force) += nout.DvDt;
			// Summ all internal energy contributions from the neighbors
			add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
		}*/
	}
};


/// Specialization of particle-particle interaction for fluid-vertex with SA boundaries
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, SA_BOUNDARY, visctype, simflags, PT_FLUID, PT_VERTEX>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		if (!(simflags & ENABLE_DENSITY_SUM)) {
			// Computes d\rho/dt, including ferrari correction
			compute_density_derivative<densitydiffusiontype, SA_BOUNDARY, PT_FLUID, PT_VERTEX>::with(params, pdata, ndata, pout, nout);
		}

		// Compute pressure part of acceleration
		compute_pressure_contrib<SA_BOUNDARY, PT_FLUID, PT_VERTEX>::with(params, pdata, ndata, pout, nout);

		// Compute viscous forces
		compute_viscous_contrib<SA_BOUNDARY, sph_formulation, PT_FLUID, PT_VERTEX>::with(params, pdata, ndata, pout, nout);

		// Compute diffusion terms for k-epsilon and the strain rate tensor
		compute_keps_term<SA_BOUNDARY, visctype, PT_FLUID, PT_VERTEX>::with(params, pdata, ndata, pout, nout);

		// Sum all contributions from the neighbors in the force array
		as_float3(pout.force) += nout.DvDt;
		// Summ all internal energy contributions from the neighbors
		add_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(pout, ndata, nout);
	}
};

/// Specialization of particle-particle interaction for fluid-boundary with SA boundaries
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	ViscosityType visctype,
	flag_t simflags>
struct compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, SA_BOUNDARY, visctype, simflags, PT_VERTEX, PT_BOUNDARY>
{
	template<typename FP, typename P, typename N, typename OP, typename ON>
	__device__ __forceinline__
	static void
	with(FP const& params, P const& pdata, N const & ndata, OP & pout, ON & nout)
	{
		// Compute gamma_as and |grad gamma_as| and add it to the respective values
		// of the focal particle
		compute_gamma<SA_BOUNDARY, PT_VERTEX, USING_DYNAMIC_GAMMA(simflags)>::with(params, pdata, ndata, pout, nout);
	}
};

/************************************************************************************************************/
/*		   Kernels for computing forces with the different options											*/
/************************************************************************************************************/
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags,
	ParticleType cptype,
	ParticleType nptype>
__global__ void
forcesDevice(
	forces_params<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, cptype, nptype> params)
{
	// Global particle index
	const uint index = INTMUL(blockIdx.x,blockDim.x) + threadIdx.x + params.fromParticle;


	// The body of this kernel easily gets a lot of indentation. to prevent that,
	// we wrap the main part into a do { } while(0); so that rather than
	// if (c1) { if (c2) { if (c3) { stuff } } } we can do
	// if (!c1) break; if (!c2) break ; if (!c3) break; stuff
	// to do stuff only if c1, c2, c3 are satisfied.
	// This makes the code more readable and collects common data retrieval operations
	// into one place.
	// (The alternative would have been a label before the reduction and a
	// bunch of goto label, but that would skip across initializations, which is an error.
	// and some people still don't like goto's, so this is actually a better alternative).
#pragma unroll
	do {
		if (index >= params.toParticle) break;

		// Particle info struct, always stored in a texture
		const particleinfo info = tex1Dfetch(infoTex, index);

		// Skip if the current particle is not of the type for which we are computing interactions
		if (PART_TYPE(info) != cptype) break;


		// Cell-local position of the particle, stored in texture
		// or global memory depending on architecture
		#if PREFER_L1
		const float4 pos = params.posArray[index];
		#else
		const float4 pos = tex1Dfetch(posTex, index);
		#endif

		// Nothing to do if the particle is inactive
		if (INACTIVE(pos))
			break;

		// Loading the rest of particle data
		forces_particle_data<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, cptype, nptype> const
			pdata(index, pos, info, params);

		// Preparing particle output variables
		forces_particle_output<boundarytype, visctype, simflags, cptype, nptype> pout(params, index);

		/* And finally the neighbors list traversal support */

		// Under some conditions, some particles might want to skip the
		// neighbor list traversal. This is checked by the check() function of
		// the skip_neiblist struct. Any action that needs to be done then is
		// done by the prepare() function in the same struct.

		skip_neiblist<boundarytype, cptype, nptype> skip;

		bool cont = true;
		if (skip.check(params, pdata)) {
			skip.prepare(pdata, pout);
			cont = false; // Skip neighbors loop
		}

		// Loop over all neighbors of type nptype
		if (cont) for_each_neib(nptype, index, pdata.pos, pdata.gridPos, params.cellStart, params.neibsList) {
			const uint neib_index = neib_iter.neib_index();

			// Compute relative position vector and distance
			// WARNING: relPos is a float4 and neib mass is stored in relPos.w
			const float4 relPos = neib_iter.relPos(
			#if PREFER_L1
				params.posArray[neib_index]
			#else
				tex1Dfetch(posTex, neib_index)
			#endif
				);

			// Skip inactive particles
			if (INACTIVE(relPos))
				continue;

			const float r = length3(relPos);

			const particleinfo neib_info = tex1Dfetch(infoTex, neib_index);

			// Bail out if we do not interact with this neighbor
			if (boundarytype == SA_BOUNDARY && nptype == PT_BOUNDARY) {
				if (r >= params.influenceradius + params.deltap)
					continue;
			}
			else if (r >= params.influenceradius)
				continue;

			// Load rest of neib data
			forces_neib_data<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, cptype, nptype> const
				ndata(pdata, params, neib_index, neib_info, relPos, r);

			// Contributions from this neighbor
			forces_neib_output<boundarytype> nout;

			// Now compute the interactions based on pdata.info and ndata.info
			compute_pp_interaction<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags, cptype, nptype>::
				with(params, pdata, ndata, pout, nout);

		} // End of loop over neighbors

		// TODO: check what to do with gamma
		write_gamma<boundarytype, nptype, USING_DYNAMIC_GAMMA(simflags)>::with(params, pdata, pout);
		write_gamma_cfl(params, pdata, pout);

		write_forces<boundarytype>::with(params, pdata, pout);

		if (nptype == PT_FLUID && cptype == PT_FLUID) {
			write_xsph<simflags & ENABLE_XSPH>::with(params, pdata, pout);
			write_turbvisc<visctype>::with(params, pdata, pout);
		}

		write_internal_energy<simflags & ENABLE_INTERNAL_ENERGY>::with(params, pdata, pout);

	} while (0);
}


// TODO FIXME splitneibs merge: load partial internal energy and store final
template<SPHFormulation sph_formulation,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags>
__global__ void
finalizeforcesDevice(
	finalize_forces_params<sph_formulation, boundarytype, visctype, simflags> params)
{
	// Global particle index
	const uint index = INTMUL(blockIdx.x,blockDim.x) + threadIdx.x + params.fromParticle;

	// Allocating shared data in case of adaptive time step
	__shared__ forces_shared_data<boundarytype, visctype, simflags> shared;
	shared.init();

#pragma unroll
	do {
		if (index >= params.toParticle) break;

		// Particle info struct, always stored in a texture
		const particleinfo info = tex1Dfetch(infoTex, index);

		const ParticleType part_type = PART_TYPE(info);

		// Cell-local position of the particle, stored in texture
		// or global memory depending on architecture
		#if PREFER_L1
		const float4 pos = params.posArray[index];
		#else
		const float4 pos = tex1Dfetch(posTex, index);
		#endif

		// Nothing to do if the particle is inactive
		if (INACTIVE(pos))
			break;

		// Loading the rest of particle data
		finalize_forces_particle_data<sph_formulation, boundarytype, visctype, simflags> const
			pdata(index, pos, info, params);

		// Preparing particle output variables
		finalize_particle_output<boundarytype, simflags> pout(params, index);

		// For SA_BOUNDARY: divides forces by gamma; else: does nothing
		if (boundarytype == SA_BOUNDARY && FLUID(pdata.info))
			gamma_fixup<boundarytype>::with(params, pdata, pout);

		// common division or multiplication
		forces_fixup<sph_formulation>::with(params, pdata, pout);

		// External forces
		if (FLUID(pdata.info)) {
			// Post-processing for viscous terms, returns viscous coefficient
			// to be used with planes/DEM

			// For KEPS: finalizes computation of strain rate & computes de/dt and dk/dt
			const float dynvisc = viscous_fixup<visctype>::with(params, pdata, pout);

			// Adding gravity
			as_float3(pout.force) += d_gravity;

			// TODO: check for time step limitation in case of geometrical boundaries (DEM or planes)
			// for viscous fluids
			float geom_coeff = 0.0f;

			// Adding repulsive force computed from DEM
			if (simflags & ENABLE_DEM) {
				switch (boundarytype) {
				case LJ_BOUNDARY:
					geom_coeff = DemLJForce(demTex, pdata.gridPos, as_float3(pdata.pos),
						pdata.pos.w, as_float3(pdata.vel), dynvisc, pout.force);
					break;
				default:
					break;
				}
			}

			// Adding repulsive force computed from geometric boundaries
			if (simflags & ENABLE_PLANES && d_numplanes) {
				geom_coeff = max(geom_coeff,
					GeometryForce(pdata.gridPos, as_float3(pdata.pos),
							pdata.pos.w, as_float3(pdata.vel), dynvisc, pout.force));
			}

			shared.store(params, pdata, pout);
		}
#if 0
		else
		if (boundarytype == SA_BOUNDARY && FLOATING(pdata.info) && BOUNDARY(pdata.info)) {
			// For SA_BOUNDARY: compute force acting on boundary
			compute_boundary_force<boundarytype>::with(params, pdata, pout);
		}
#endif


		// Writing out the results
		// NOTE: with SA bounds only boundary elements compute and write object forces, not vertices.
		if (COMPUTE_FORCE(pdata.info) && !VERTEX(pdata.info)) {
			// Except for SA boundary, the forces computed in the neighbors loop are forces by unit of mass
			// (i.e) accelerations so when we computing the total forces (and torques) acting on an object
			// particle, the force must be multiplied by the particle mass.

			// TODO
			// 1. use relative coordinates for cg and distance computation
			// 2. the write of forces and torques is by nature not coalesced so why using float4
			// 3. params and the kernel should be templatized also on floating bodies presence
			// AM - GB FIXME
			if (boundarytype != SA_BOUNDARY)
				as_float3(pout.force) *= pdata.pos.w;
			params.rbforces[pdata.rbindex] = pout.force;

			const float3 arm = globalDistance(pdata.gridPos, as_float3(pdata.pos),
					d_rbcgGridPos[object(info)], d_rbcgPos[object(info)]);

			params.rbtorques[pdata.rbindex] = make_float4(cross(arm, as_float3(pout.force)));

		}

		write_forces<boundarytype>::with(params, pdata, pout);

	} while (0);

	shared.reduce(params);
}

//***********************************************************************************************************
// Structures and kernels for the computation of the density diffusion, used in the ENABLE_DENSITY_SUM case.
// This relies on the compute_density_diffusion functor (shared with forcesDevice) for the actual computation,
// after defining its own set of particle_data and particle_output structures.
//***********************************************************************************************************

struct gamma_particle_data
{
	const float4 ggam;

	template<typename FP> /* templatized over the kernel input params */
	__device__ __forceinline__
	gamma_particle_data(FP const& params, const uint _index) :
		ggam(params.ggam[_index])
	{}
};

template<BoundaryType boundarytype>
struct density_diffusion_particle_data :
	common_particle_data,
	vel_particle_data,
	COND_STRUCT(boundarytype == SA_BOUNDARY, gamma_particle_data)
{
	template<typename FP> /* templatized over the kernel input params */
	__device__ __forceinline__
	density_diffusion_particle_data(FP const& params, const uint _index, float4 const& _pos, particleinfo const& _info) :
		common_particle_data(_index, _pos, _info, params.particleHash),
		vel_particle_data(params, _index, _info),
		gamma_particle_data(params, _index)
	{}
};

template<BoundaryType boundarytype>
struct density_diffusion_neib_data :
	common_neib_data,
	COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_data)
{
	/* TODO */
	template<typename Pt, typename FP>
	__device__ __forceinline__
	density_diffusion_neib_data(Pt const& pdata, FP const& params,
		const uint _index, particleinfo const& _info,
		float4 const& _relPos, const float _r) :
		common_neib_data(pdata, params, _index, _info, _relPos, _r),
		COND_STRUCT(boundarytype == SA_BOUNDARY, sa_boundary_neib_data)(pdata, params, _index, _relPos)
	{}
};

struct common_density_diffusion_neib_output
{
	float DrDt;

	__device__ __forceinline__
	common_density_diffusion_neib_output() : DrDt(0.0f) {}
};

struct sa_boundary_density_diffusion_neib_output
{
	const float ggamAS;

	template<typename FP, typename P, typename N>
	__device__ __forceinline__
	sa_boundary_density_diffusion_neib_output
	(FP const& params, P const& pdata, N const& ndata) :
		ggamAS(compute_gamma
			<FP::boundarytype, FP::cptype, true>::gradient
			(params, pdata, ndata))
	{}
};

template<BoundaryType boundarytype, ParticleType nptype,
	bool needs_ggam = (boundarytype == SA_BOUNDARY && nptype == PT_BOUNDARY)>
struct density_diffusion_neib_output :
	common_density_diffusion_neib_output,
	COND_STRUCT(needs_ggam, sa_boundary_density_diffusion_neib_output)
{
	template<typename FP, typename P, typename N>
	__device__ __forceinline__
	density_diffusion_neib_output
	(FP const& params, P const& pdata, N const& ndata) :
		common_density_diffusion_neib_output(),
		COND_STRUCT(needs_ggam, sa_boundary_density_diffusion_neib_output)
		(params, pdata, ndata)
	{}
};

/* Return the contribution to the density diffusion from all neighbors of type nptype.
 * Note that there is no contribution from the VERTEX particles except in the SA_BOUNDARY case;
 * this is handled by the enable_if
 */
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags,
	ParticleType cptype,
	ParticleType nptype>
__device__ __forceinline__
typename std::enable_if<nptype != PT_VERTEX || boundarytype == SA_BOUNDARY, void>::type
density_diffusion_interaction(
	density_diffusion_params<kerneltype, densitydiffusiontype, boundarytype, cptype> const& params,
	density_diffusion_particle_data<boundarytype> const& pdata,
	float& DrDt)
{
	for_each_neib(nptype, pdata.index, pdata.pos, pdata.gridPos, params.cellStart, params.neibsList) {
		const uint neib_index = neib_iter.neib_index();
		const float4 relPos = neib_iter.relPos(params.posArray[neib_index]);
		const float r = length3(relPos);
		const particleinfo neib_info = params.infoArray[neib_index];

		if (INACTIVE(relPos)) continue;
		if (boundarytype == SA_BOUNDARY && nptype == PT_BOUNDARY) {
			if (r >= params.influenceradius + params.deltap)
				continue;
		} else {
			if (r >= params.influenceradius)
				continue;
		}

		const density_diffusion_neib_data<boundarytype> ndata(pdata, params, neib_index, neib_info, relPos, r);

		density_diffusion_neib_output<boundarytype, nptype> nout(params, pdata, ndata);

		compute_density_diffusion<densitydiffusiontype, boundarytype, cptype, nptype>::with(params, pdata, ndata, nout);

		DrDt += nout.DrDt;
	}
}

/* The "no contribution” case, i.e. nptype == PT_VERTEX && boundarytype != SA_BOUNDARY */
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags,
	ParticleType cptype,
	ParticleType nptype>
__device__ __forceinline__
typename std::enable_if<nptype == PT_VERTEX && boundarytype != SA_BOUNDARY, void>::type
density_diffusion_interaction(
	density_diffusion_params<kerneltype, densitydiffusiontype, boundarytype, cptype> const& params,
	density_diffusion_particle_data<boundarytype> const& pdata,
	float &DrDt)
{ /* do nothing */ }


/* Compute density diffusion ONLY (used in the ENABLE_DENSITY_SUM case) */
template<KernelType kerneltype,
	SPHFormulation sph_formulation,
	DensityDiffusionType densitydiffusiontype,
	BoundaryType boundarytype,
	ViscosityType visctype,
	flag_t simflags,
	ParticleType cptype>
__global__ void
computeDensityDiffusionDevice(density_diffusion_params<kerneltype, densitydiffusiontype, boundarytype, cptype> params)
{
	// Global particle index
	const uint index = INTMUL(blockIdx.x,blockDim.x) + threadIdx.x;

	if (index >= params.particleRangeEnd) return;

	// Particle info struct, always stored in a texture
	const particleinfo info = params.infoArray[index];

	// Skip if the current particle is not of the type for which we are computing interactions
	if (PART_TYPE(info) != cptype) return;

	const float4 pos = params.posArray[index];

	// Nothing to do if the particle is inactive
	if (INACTIVE(pos)) return;

	const density_diffusion_particle_data<boundarytype> pdata(params, index, pos, info);

	float DrDt = 0;

	density_diffusion_interaction
		<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags,
		cptype, PT_FLUID>(params, pdata, DrDt);
	density_diffusion_interaction
		<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags,
		cptype, PT_VERTEX>(params, pdata, DrDt);
	density_diffusion_interaction
		<kerneltype, sph_formulation, densitydiffusiontype, boundarytype, visctype, simflags,
		cptype, PT_BOUNDARY>(params, pdata, DrDt);

	params.forces[index].w = DrDt;
}

#endif

/* vi:set ft=cuda: */

